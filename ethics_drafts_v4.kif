;; I'll start with the latest version of Deciding

;; It seems helpful to have a wrapper for classes that allows them to be treated as instances.
;; Sort of an inverse of the KappaFn?  -- I think for the reverse direction, KappaFn should be used.
;; I would wish to define a subclass of Set for Sets of Instances to make the type checking easier.
(documentation ClassToSetFn EnglishLanguage "A UnaryFunction that maps a Class into the set of instances of the Class.")
(domainSubclass ClassToSetFn 1 Class)
(instance ClassToSetFn TotalValuedRelation)
(instance ClassToSetFn UnaryFunction)
(range ClassToSetFn Set)

(<=>
  (element ?INSTANCE (ClassToSetFn ?CLASS))
  (instance ?INSTANCE ?CLASS))
        
;; All patients of deciding are sets corresponding to classes of intentional processes.
(=>
  (and
    (instance ?DECIDE Deciding)
    (patient ?DECIDE ?OPTIONSET))
  (exists (?CLASS)
    (and
      (equal (ClassToSetFn ?CLASS) ?OPTIONSET)
      (subclass ?CLASS IntentionalProcess))))

(=>
  (and
    (instance ?DECIDE Deciding)
    (agent ?DECIDE ?AGENT)
    (patient ?DECIDE (ClassToSetFn ?OPTION)))
  (believes ?AGENT
    (capability ?OPTION agent ?AGENT)))

(=>
  (and
    (instance ?DECIDE Deciding)
    (agent ?DECIDE ?AGENT)
    (result ?DECIDE (ClassToSetFn ?DECISION)))
  (believes ?AGENT
    (holdsDuring
      (FutureFn
        (WhenFn ?DECIDE))
      (exists (?P)
        (and
          (instance ?P ?DECISION)
          (agent ?P ?AGENT)
          (earlier
            (WhenFn ?DECIDE)
            (WhenFn ?P)))))))


;; And the 'alternative' set of classes approach to make it easier to find and reference.
;; Suppose we go with the idea to represent the set of options in a decision in terms of a set.
;; Then we want to say that all the elements thereof are intentional processes.                                      
; (=>
;   (and
;     (instance ?DECIDE Deciding)
;     (instance ?S Set)
;     (patient ?DECIDE ?S)
;     (element ?O ?S))
;   (subclass ?O IntentionalProcess))

;; For every instance of deciding, there is a non-empty set over which one is deciding.
; (=>
;   (instance ?DECIDE Deciding)
;   (exists (?S)
;     (and
;       (instance ?S NonNullSet)
;       (patient ?DECIDE ?S))))

;; For every option in a decision set for an agent,
;; the agent believes itself capable of performing this option.   
; (=>
;   (and
;     (instance ?DECIDE Deciding)
;     (agent ?DECIDE ?AGENT)
;     (instance ?S Set)
;     (patient ?DECIDE ?S)
;     (element ?O ?S))
;     (believes ?AGENT 
;       (capability ?O agent ?AGENT)))

;;  For every resulting decision set element, the agent believes it will enact that behavior in the future.  
; (=>
;   (and 
;     (instance ?DECIDE Deciding)
;     (agent ?DECIDE ?AGENT)
;     (result ?DECIDE ?DECISION)
;     (instance ?DECISION Set)
;     (element ?O ?S))
;   (believes ?AGENT
;     (holdsDuring 
;       (FutureFn
;         (WhenFn ?DECIDE))
;       (exists (?P)
;         (and
;           (instance ?P ?O)
;           (agent ?P ?AGENT))))))

;; The resulting decision-set is a subset of some decision set being decided over.       
; (=>
;   (and 
;     (instance ?DECIDE Deciding)
;     (result ?DECIDE ?DECISION)
;     (instance ?DECISION Set))
;   (exists (?S)
;     (and
;       (patient ?DECISION ?S)
;       (subset ?DECISION ?S))))

;; This should ontologically work for the Virtue ethics case without providing a specific measure.
(documentation similar EnglishLanguage "The predicate similar attempts to capture the ontologic notion of similarity 
from a subjective point of view. (similar ?A ?E1 ?E2) means that ?E1 and ?E2 are similar to cognitive agent ?A.")
(instance similar TernaryPredicate)  
(domain similar 1 CognitiveAgent)
(domain similar 2 Entity)
(domain similar 3 Entity)

(=>
  (similar ?A ?E1 ?E2)
  (forall (?J1 ?J2 ?O1 ?O2)
    (=>
      (and
        (instance ?J1 Judging)
        (instance ?O1 Formula)
        (agent ?J1 ?A)
        (patient ?J1 ?E1)
        (result ?J1 ?O1)
        (instance ?J2 Judging)
        (instance ?O2 Formula)
        (agent ?J2 ?A)
        (patient ?J2 ?E2)
        (result ?J2 ?O2))
      (modalAttribute
        (similar ?A ?O1 ?O2) Likely))))

;; This might help.
(=>
  (equal ?E1 ?E2)
  (forall (?A)
    (similar ?A ?E1 ?E2)))

(<=>
  (similar ?A ?E1 ?E2)
  (similar ?A ?E2 ?E1))

;; Not sure if this should be subjective or not!
(documentation relevant EnglishLanguage "The predicate relevant attempts to ontologically represent the notion of 
an entity ?E1 being relevant to ?E2: (relevant ?E1 ?E2). Relevant: having a bearing on or connection with the 
subject at issue; 'the scientist corresponds with colleagues in order to learn about matters relevant to her 
own research'.")
(instance relevant BinaryPredicate)  
(domain relevant 1 Entity)
(domain relevant 2 Entity)

;; The patient of a process is relevant to the process.
(=>
  (and
    (instance ?E2 Process)
    (patient ?E2 ?E1))
  (relevant ?E1 ?E2))

;; If an Object plays some role in a Process, then it is relevant to the process.
(=> 
  (and
    (instance ?E1 Object)
    (instance ?E2 Process)
    (exists (?ROLE)
      (playsRoleInEvent ?E1 ?ROLE ?E2)))
  (relevant ?E1 ?E2))

(=> 
  (and 
    (instance ?E1 Object)
    (instance ?E2 Process)
    (eventLocated ?E2 ?E1))
  (relevant ?E1 ?E2))

(documentation Situation EnglishLanguage "A spatiotemporal situation in which something occurs or exists.")
(subclass Situation Physical)

;; Probably too storng
;; For every situation, the location of the beginning and end of the time interval of the situation is the same.
(=>
  (instance ?S Situation)
  (and 
    (equal ?T (WhenFn ?S))
    (equal (WhereFn ?S (BeginFn ?T)) (WhereFn ?S (EndFn ?T)))))

(documentation CapableInSituation EnglishLanguage "(CapableInSituation ?TYPE ?ROLE ?OBJECT ?SITUATION) 
means that ?OBJECT has the ability to play the CaseRole ?ROLE in Processes of ?TYPE in ?SITUATION.")

(<=>
  (CapableInSituation ?TYPE ?ROLE ?OBJECT ?SITUATION)
  (and
    (equal ?TIME (WhenFn ?S))
    (equal ?LOCATION (WhereFn (BeginFn ?TIME))) 
    (capabilityDuring ?TYPE ?ROLE ?OBJECT ?TIME)
    (capabilityAtLocation ?TYPE ?ROLE ?OBJECT ?LOCATION)))

;; Now maybe I want a SituationFn that given some physical entity returns the situation?
;; Yeah, this is a fabulous catch-all!
(documentation SituationFn EnglishLanguage "Maps a Physical Entity to its Situation.  May be non-deterministic 
because situations have one enduring region whereas a process could cover multiple regions.")
(domain SituationFn 1 Physical)
(range SituationFn Situation)
(instance SituationFn UnaryFunction)
(instance SituationFn TotalValuedRelation)
(relatedInternalConcept SituationFn WhereFn)
(relatedInternalConcept SituationFn WhenFn)

(documentation MoralAttribute EnglishLanguage "Moral Attributes are a subclass of Normative Attributes intended to denote whether something is Good, Bad, Right, Wrong, Virtuous, Viceful, or other moral attributes.")
(subclass MoralAttribute NormativeAttribute)

(documentation MoralValueAttribute EnglishLanguage "Moral Value Attributes are a subclass of Moral Attributes dealing with the attribution of value: whether something is good, bad, or netural.")
(subclass MoralValueAttribute MoralAttribute)

(instance MorallyGood MoralValueAttribute)
(instance MorallyBad MoralValueAttribute)
(instance MorallyNeutral MoralValueAttribute)

(documentation MoralVirtueAttribute EnglishLanguage "Moral Virtue Attributes are a subclass of Moral Attributes dealing with the virtues and vices.")
(subclass MoralVirtueAttribute MoralAttribute)

(subclass VirtueAttribute MoralVirtueAttribute)
(subclass ViceAttribute MoralVirtueAttribute)

(subclass VirtueAttribute PsychologicalAttribute)
(subclass ViceAttribute PsychologicalAttribute)

;; Do we want a moral attribute for utilitarianism?

;; Generally speaking, yes.  Might some paraconsistency reign?  :- p
(contraryAttribute MorallyGood MorallyBad)
(contraryAttribute MorallyGood MorallyNeutral)
(contraryAttribute MorallyBad MorallyNeutral)
(contraryAttribute VirtueAttribute ViceAtribute)

;; Why not say it explicitly, too.  
(=>
  (modalAttribute ?F MorallyGood)
  (not (modalAttribute ?F MorallyBad)))
  
(=>
  (modalAttribute ?F MorallyGood)
  (not (modalAttribute ?F MorallyNeutral)))
  
(=>
  (modalAttribute ?F MorallyBad)
  (not (modalAttribute ?F MorallyGood)))
  
(=>
  (modalAttribute ?F MorallyBad)
  (not (modalAttribute ?F MorallyNeutral)))
  
(=>
  (modalAttribute ?F MorallyNeutral)
  (not (modalAttribute ?F MorallyGood)))
  
(=>
  (modalAttribute ?F MorallyNeutral)
  (not (modalAttribute ?F MorallyBad)))

(documentation VirtuousAgent EnglishLanguage "'A virtuous agent is one who has, and exercises, certain character traits, namely, the virtues.' (On Virtue Ethics)")
(subclass VirtuousAgent AutonomousAgent)

;; Draft 3: Note that it is quantifying over all virtues!  
;; A very strong requirement for a virtuous agent, lol.
(=>
  (and
    (instance ?AGENT AutonomousAgent)
    (instance ?VIRTUE VirtueAttribute)
    (attribute ?AGENT ?VIRTUE))
  (instance ?AGENT VirtuousAgent))

;; Draft 4: This version seems better: an agent posessing a virtue increases the likelihood that the agent is virtuous ;- ).
(increasesLikelihood
  (exists (?VIRTUE)
    (and
      (instance ?AGENT AutonomousAgent)
      (instance ?VIRTUE VirtueAttribute)
      (attribute ?AGENT ?VIRTUE)))
  (instance ?AGENT VirtuousAgent))
  
(=>
  (instance ?AGENT VirtuousAgent)
  (exists (?VIRTUE)
    (attribute ?AGENT ?VIRTUE)))
  
(documentation ViciousAgent EnglishLanguage "A vicious agent is one who has, and exercises, certain character traits, namely, the vices.  The antonym of VirtuousAgent.")
(subclass ViciousAgent AutonomousAgent)

(=>
  (and
    (instance ?AGENT AutonomousAgent)
    (instance ?VICE ViceAttribute)
    (attribute ?AGENT ?VICE))
  (instance ?AGENT ViciousAgent))
  
(increasesLikelihood
  (exists (?VICE)
    (and
      (instance ?AGENT AutonomousAgent)
      (instance ?VICE ViceAttribute)
      (attribute ?AGENT ?VICE)))
  (instance ?AGENT ViciousAgent))
  
(=>
  (instance ?AGENT ViciousAgent)
  (exists (?VICE)
    (attribute ?AGENT ?VICE)))

;; Encapsulate the Autonomous Agent aspect of "behavior"-type processes.
(documentation AutonomousAgentProcess EnglishLanguage "AgentProcess is the Class of all Processes in which there is an autonomous agent.")
(subclass AutonomousAgentProcess Process)
(subclass BodyMotion AutonomousAgentProcess)
(subclass Vocalizing AutonomousAgentProcess)

(=>
  (instance ?PROC AutonomousAgentProcess)
  (exists (?AGENT)
    (and
      (agent ?PROC ?AGENT)
      (instance ?AGENT AutonomousAgent))))

;; A theory is a set of sentences (in a formal language).
(documentation Theory EnglishLanguage "A set of sentences.")
(subclass Theory Set)

(<=>
  (instance ?T Theory)
  (forall (?S)
    (=>
      (element ?S ?T)
      (instance ?S Sentence))))

;; Maybe I should change all the sentences to Formulas
(documentation SentenceList EnglishLanguage "A list of Sentences.")
(subclass SentenceList List)

(=>
  (and
    (instance ?LIST SentenceList)
    (inList ?SENTENCE ?LIST))
  (instance ?SENTENCE Sentence))

(documentation ListAndFn EnglishLanguage "The and-concatenation of all the sentences in a SentenceList.")
(domain ListAndFn 1 SentenceList)
(instance ListAndFn UnaryFunction)
(range ListAndFn Sentence)

(=>
  (and
    (equal ?S
      (ListAndFn ?L))
    (equal 1
      (ListLengthFn ?L)))
  (equal ?S
    (ListOrderFn ?L 1)))

(=>
  (and
    (equal ?S
      (ListAndFn ?L))
    (greaterThan
      (ListLengthFn ?L) 1))
  (equal ?S
    (and
      (FirstFn ?L)
      (ListAndFn
        (SubListFn 2
          (ListLengthFn ?L) ?L)))))

(documentation SetToListFn EnglishLanguage "A function that converts a set into a list.  The order is unspecified.")
(instance SetToListFn UnaryFunction)
(domain SetToListFn 1 Set)
(range SetToListFn List)

;; If StL(S) = L, then S and L share all their members and their sizes are equal.
;; This says nothing about the order.
(=>
  (equal
    (SetToListFn ?SET) ?LIST)
  (and
    (equal
      (ListLengthFn ?LIST)
      (CardinalityFn ?SET))
    (forall (?ELEMENT)
      (<=>
        (element ?ELEMENT ?SET)
        (inList ?ELEMENT ?LIST)))))

(documentation MoralTheory EnglishLanguage "A set of sentences in a moral theory")
(subclass MoralTheory Theory)

;; Insert rules
;; I'm tempted to partition it but that's crude as there is at least one paradigm I haven't covered (morally nihilistic theories).

;; Maybe I should have a "theory of type X" predicate instead but this seems cleaner.
(documentation MoralSentence EnglishLanguage "A sentence of a moral theory")
(subclass MoralSentence Sentence)

(<=>
  (instance ?SENTENCE MoralSentence)
  (exists (?THEORY)
    (and
      (instance ?THEORY MoralTheory)
      (element ?SENTENCE ?THEORY))))

(documentation DeontologicalTheory EnglishLanguage "A set of sentences assigning moral attributes.")
(subclass DeontologicalTheory MoralTheory)

(documentation DeontologicalSentence EnglishLanguage "A sentence of a deontological language/theory.")      
(subclass DeontologicalSentence MoralSentence)

(<=>
  (instance ?SENTENCE DeontologicalSentence)
  (exists (?THEORY)
    (and
      (instance ?THEORY DeontologicalTheory)
      (element ?SENTENCE ?THEORY))))


(documentation ValueJudgmentSentence EnglishLanguage "A sentence that describes the attribution of a moral value judgment.")      
(subclass ValueJudgmentSentence MoralSentence)

(documentation SimpleValueJudgmentSentence EnglishLanguage "A sentence that describes the attribution of a moral value judgment.")      
(subclass SimpleValueJudgmentSentence ValueJudgmentSentence)

(<=>
  (instance ?SENTENCE SimpleValueJudgmentSentence)
  (exists (?F ?MORALATTRIBUTE)
    (and
      (equal (modalAttribute ?F ?MORALATTRIBUTE) ?SENTENCE)
      (instance ?F Formula)
      (or
        (equal ?MORALATTRIBUTE MorallyGood)
        (equal ?MORALATTRIBUTE MorallyBad)
        (equal ?MORALATTRIBUTE MorallyNeutral)))))

;; So now that I defined MoralValueAttribute, this can be simplified!        
(<=>
  (instance ?SENTENCE SimpleValueJudgmentSentence)
  (exists (?F ?MORALATTRIBUTE)
    (and
      (equal (modalAttribute ?F ?MORALATTRIBUTE) ?SENTENCE)
      (instance ?F Formula)
      (instance ?MORALATTRIBUTE MoralValueAttribute))))

;; The definition of ethics is that it focuses on judging actions.
(documentation SimpleActionValueJudgmentSentence EnglishLanguage "A sentence that describes the attribution of a moral value judgment to an action.")      
(subclass SimpleActionValueJudgmentSentence SimpleValueJudgmentSentence)

(<=>
  (instance ?SENTENCE SimpleActionValueJudgmentSentence)
  (exists (?CLASS ?FORMULA ?MORALATTRIBUTE)
    (and 
      (equal ?SENTENCE (modalAttribute ?FORMULA ?MORALATTRIBUTE))
      (equal ?FORMULA 
        (exists (?PROC)
          (instance ?PROC ?CLASS)))
      (subclass ?CLASS AutonomousAgentProcess))))

(<=>
  (instance ?SENTENCE ValueJudgmentSentence)
  (exists (?VJS)
    (and
      (instance ?VJS SimpleValueJudgmentSentence)
      (part ?VJS ?SENTENCE))))

(documentation ImperativeSentence EnglishLanguage "A sentence that describes an imperative deontic operator.")      
(subclass ImperativeSentence DeontologicalSentence)    

(documentation SimpleImperativeSentence EnglishLanguage "A sentence that describes an imperative deontic operator.")      
(subclass SimpleImperativeSentence ImperativeSentence)

(<=>
  (instance ?SENTENCE SimpleImperativeSentence)
  (exists (?F ?DEONTICATTRIBUTE)
        (and
          (equal (modalAttribute ?F ?DEONTICATTRIBUTE) ?SENTENCE)
          (instance ?F Formula)
          (instance ?DEONTICATTRIBUTE DeonticAttribute))))

(<=>
  (instance ?SENTENCE ImperativeSentence)
  (exists (?IT)
    (and
      (instance ?IT SimpleImperativeSentence)
      (part ?IT ?SENTENCE))))

(documentation ValueJudgmentTheory EnglishLanguage "A set of sentences assigning moral attributes.")
(subclass ValueJudgmentTheory DeontologicalTheory)

;; A deontological theory is one where for every sentence, there exists a formula and moral attribute 
;; such that the sentence assigns this  moral attribute to the formula.
;;  I think the inverse direction works for the Virtue and Utilitarian approaches as we're not quantifying over general formulas.
;; Yet I am not fully sure how I wish to constrain formulas.
;; Existential formulas over processes or physical entities or... what?
(=>
  (instance ?D ValueJudgmentTheory)
  (forall (?S)
    (=>
      (element ?S ?D)
      (exists (?F ?MORALATTRIBUTE)
        (and
          (equal ?S
            (modalAttribute ?F ?MORALATTRIBUTE))
          (instance ?F Formula)
          (or
            (equal ?MORALATTRIBUTE MorallyGood)
            (equal ?MORALATTRIBUTE MorallyBad)))))))

;; The above is too strong.  The sentence may describe the context in which the moral judgment is being dished out.
(=>
  (instance ?D ValueJudgmentTheory)
  (forall (?S)
    (=>
      (element ?S ?D)
      (exists (?F ?MORALATTRIBUTE)
        (and
          (part (modalAttribute ?F ?MORALATTRIBUTE) ?S)
          (instance ?F Formula)
          (or
            (equal ?MORALATTRIBUTE MorallyGood)
            (equal ?MORALATTRIBUTE MorallyBad)
            (equal ?MORALATTRIBUTE MorallyNeutral)))))))

;; Now I can simplify things and say that a Deontological Value Judgment Theory is one in which all sentences contain a value judgment sentence as a part!
(=>
  (instance ?D ValueJudgmentTheory)
  (forall (?S)
    (=>
      (element ?S ?D)
      (instance ?S ValueJudgmentSentence))))
            
(documentation DeontologicalImperativeTheory EnglishLanguage "A set of sentences containing moral imperatives.")
(subclass DeontologicalImperativeTheory DeontologicalTheory)

(=> 
  (instance ?MT DeontologicalImperativeTheory)
  (forall (?S)
    (=>
      (element ?S ?MT)
      (instance ?S ImperativeSentence))))
 
(documentation VirtueEthicsTheory EnglishLanguage "A set of sentences assigning virtue or vice attributes.")
(subclass VirtueEthicsTheory MoralTheory)

(documentation VirtueEthicsSentence EnglishLanguage "A sentence of a virtue ethics language/theory.")      
(subclass VirtueEthicsSentence MoralSentence)

(<=>
  (instance ?SENTENCE VirtueEthicsSentence)
  (exists (?THEORY)
    (and
      (instance ?THEORY VirtueEthicsTheory)
      (element ?SENTENCE ?THEORY))))

(documentation SimpleVirtueSentence EnglishLanguage "A sentence that describes an virtue/vice attribute assignment to an agent.")      
(subclass SimpleVirtueSentence VirtueEthicsSentence)    

(<=>
  (instance ?SENTENCE SimpleVirtueSentence)
  (exists (?AGENT ?VIRTUEATTRIBUTE)
    (and
      (equal ?SENTENCE (attribute ?AGENT ?VIRTUEATTRIBUTE))
      (instance ?AGENT AutonomousAgent)
      (instance ?VIRTUEATTRIBUTE MoralVirtueAttribute))))

(<=>
  (insance ?SENTENCE VirtueEthicsSentence)
  (exists (?SVS)
    (and
      (instance ?SVS SimpleVirtueSentence)
      (part ?SVS ?SENTENCE))))       

(<=>
  (instance ?V VirtueEthicsTheory)
  (forall (?S)
    (=>
      (element ?S ?V)
      (instance ?S VirtueSentence))))
            
(documentation UtilitarianTheory EnglishLanguage "A set of sentences dealing with the utility of behaviors.")
(subclass UtilitarianTheory MoralTheory)

(documentation UtilitarianSentence EnglishLanguage "A sentence of the variety of a utilitarian theory.")
(subclass UtilitarianSentence MoralSentence)

(documentation SimpleUtilitarianSentence EnglishLanguage "A sentence that assigns or compares the value of situations described by formulas.")      
(subclass SimpleUtilitarianSentence UtilitarianSentence) 

(documentation UtilityAssignmentSentence EnglishLanguage "A Sentence that assigns a (real) number value 
to a situation described by a formula.")
(subclass UtilityAssignmentSentence SimpleUtilitarianSentence)

(<=>
  (instance ?SENTENCE UtilityAssignmentSentence)
  (exists (?FORMULA ?VALUE)
    (and 
      (equal ?SENTENCE (equal (UtilityFormulaFn ?FORMULA) ?VALUE))
      (instance ?FORMULA Formula)
      (instance ?VALUE Number))))

(documentation UtilityComparisonSentence EnglishLanguage "A sentence that compares the value of 
two situations described by formulas.")
(subclass UtilityComparisonSentence SimpleUtilitarianSentence)

(<=> 
  (instance ?SENTENCE UtilityComparisonSentence)
  (exists (?FORMULA1 ?FORMULA2 ?COMPARATOR)
    (and
      (instance ?FORMULA1 Formula)
      (instance ?FORMULA2 Formula)
      (or
            (equal ?COMPARATOR greaterThan)
            (equal ?COMPARATOR lessThan)
            (equal ?COMPARATOR greaterThanOrEqualTo)
            (equal ?COMPARATOR lessThanOrEqualTo))
      (equal ?SENTENCE (?COMPARATOR (UtilityFormulaFn ?FORMULA1) (UtilityFormulaFn ?FORMULA2))))))

(<=>
  (instance ?SENTENCE SimpleUtilitarianSentence)
  (or
    (instance ?SENTENCE UtilityComparisonSentence)
    (instance ?SENTENCE UtilityAssignmentSentence)))

;; Ultimately, I will wish to weaken this so that this only represents one variety of Utilitarian theory.
(<=>
  (instance ?SENTENCE UtilitarianSentence)
  (exists (?SUS)
    (and 
      (instance ?SUS SimpleUtilitarianSentence)
      (part ?SUS ?SENTENCE))))

(<=> 
  (instance ?U UtilitiarianTheory)
  (forall (?S)
    (=>
      (element ?S ?U)
      (instance ?S UtilitarianSentence))))

;; I switched to formulas for consistency with the deontology stuff.
(<=>
  (instance ?U UtilitarianTheory)
  (forall (?S)
    (=>
      (element ?S ?U)
      (exists (?CBEHAVE ?CBEHAVE2 ?N ?C)
        (and
          (subclass ?CBEHAVE AutonomousAgentProcess)
          (subclass ?CBEHAVE2 AutonomousAgentProcess)
          (or
            (equal ?S
              (
                (?C
                  (UtilitySubclassFn ?CBEHAVE) ?N)))
            (equal ?S
              (?C
                (UtilitySubclassFn ?CBEHAVE)
                (UtilitySubclassFn ?CBEHAVE2))))
          (instance ?N Number)
          (or
            (equal ?C greaterThan)
            (equal ?C lessThan)
            (equal ?C greaterThanOrEqualTo)
            (equal ?C lessThanOrEqualTo)
            (equal ?C equal)))))))

;; This is actually really clean.  No mucking around in saying that it is judging behavioral (instances or classes), etc.
(documentation MoralJudging EnglishLanguage "A subclass of Judging where the proposition believed is 
a moral sentence from a moral theory (in a given paradigm).")
(subclass MoralJudging Judging)

(=>
  (instance ?JUDGE MoralJudging)
  (exists (?SENTENCE)
    (and
      (instance ?SENTENCE MoralSentence)
      (result ?JUDGE ?SENTENCE))))

(documentation Ethics EnglishLanguage "Ethics is the normative science of the conduct of human beings living in society, 
which judges this conduct to be right or wrong, to be good or bad, or in some similar way. (An Introduction to Ethics (Lillie, 1948))")
(subclass Ethics Philosophy)
(subclass Ethics Science) 

(and
  (refers Ethics ?JUDGE)
  (instance ?JUDGE MoralJudging))
;; The reference definition includes judging (and normativity), so referring to the theory w/o judging/interpreting the theory is
;; "Necessary but not sufficient".
(and
  (refers Ethics ?THEORY)
  (instance ?THEORY MoralTheory))
  
;; Ethics refers to the judgment by a group of a member via a moral sentence (that refers to the member).
;; It gets a bit vague abstracting out behavior, lol.  
;; Note that the English says that a subCollection is a "proper part", however there is no rule that implies this.  
(and
  (refers Ethics ?JUDGE)
  (instance ?JUDGE MoralJudging)
  (instance ?GROUP Group)
  (agent ?JUDGE ?AGENT)
  (or
    (member ?AGENT ?GROUP)
    (part ?AGENT ?GROUP))
  (member ?MEMB ?GROUP)
  (patient ?JUDGE ?SENTENCE)
  (instance ?SENTENCE MoralSentence)
  (refers ?SENTENCE ?MEMB))

;; Let's get a version that works with moral theories.
;; Ethics refers to a moral theory and a group where each sentence is believed to be true by the group
;; and each sentence refers to a behavior such that it's believed some member of the group is capable of this behavior.
(and
  (refers Ethics
    (and ?MT ?GROUP))
  (instance ?MT MoralTheory)
  (instance ?GROUP Group)
  (forall (?S)
    (=>
      (element ?S ?MT)
      (and
        (believes ?GROUP ?S)
        (refers ?S (ClassToSetFn ?B))
        (subclass ?B AutonomousAgentProcess)
        (believes ?GROUP
          (exists (?MEMB)
            (and
              (member ?MEMB ?GROUP)
              (capability ?B agent ?MEMB))))))))

;; As this 'belief' is the result of the moral judgment, we can throw moral judgments in.
;; This implies that ?S is believed.
;; However, it also implies that prior to the act of judgment, it was not believed to be so. 
;; Which implies some judgment process by which this moral sentence came to be believed.
(and
  (refers Ethics
    (and ?MT ?GROUP))
  (instance ?MT MoralTheory)
  (instance ?GROUP Group)
  (forall (?S)
    (=>
      (element ?S ?MT)
      (exists (?JUDGE)
        (and
          (instance ?JUDGE MoralJudging)
          (agent ?JUDGE ?GROUP)
          (result ?JUDGE ?S)
          (refers ?S (ClassToSetFn ?B))
          (subclass ?B AutonomousAgentProcess)
          (believes ?GROUP
            (exists (?MEMB)
              (and
                (member ?MEMB ?GROUP)
                (capability ?B agent ?MEMB)))))))))

;; Decided that by their structure, the sentences do not necessarily refer to behavior.
;; The moral judgment process may, however!
(and
  (refers Ethics
    (and ?MT ?GROUP))
  (instance ?MT MoralTheory)
  (instance ?GROUP Group)
  (forall (?S)
    (=>
      (element ?S ?MT)
      (exists (?JUDGE)
        (and
          (instance ?JUDGE MoralJudging)
          (agent ?JUDGE ?GROUP)
          (result ?JUDGE ?S)
          (refers ?JUDGE (ClassToSetFn ?B))
          (subclass ?B AutonomousAgentProcess)
          (believes ?GROUP
            (exists (?MEMB)
              (and
                (member ?MEMB ?GROUP)
                (capability ?B agent ?MEMB)))))))))

(documentation MoralNihilism EnglishLanguage "'Moral Nihilism is the view that nothing is morally wrong' (SEP - Moral Skepticism). 
Moral Nihilism can also be defined as 'the view that there are no moral facts' (Ethics: The Fundamentals).")
(subclass MoralNihilism Ethics)
  
(=>
  (instance ?MN MoralNihilism)
  (exists (?PROP ?STATE)
    (and
      (subProposition ?PROP ?MN)
      (containsInformation ?STATE ?PROP)
      (similar ?STATE
        (not
          (exists (?MORALSTATEMENT)
            (and
              (instance ?MORALSTATEMENT MoralSentence)
              (instance ?MORALSTATEMENT Fact))))))))

(=>
  (instance ?MN MoralNihilism)
  (exists (?PROP ?STATE)
    (and
      (subProposition ?PROP ?MN)
      (containsInformation ?STATE ?PROP)
      (similar ?STATE
        (not
          (exists (?BEHAVIORCLASS)
            (and
              (subclass ?BEHAVIORCLASS AutonomousAgentProcess)
              (modalAttribute
                (exists (?BEHAVIORINSTANCE)
                  (instance ?BEHAVIORINSTANCE ?BEHAVIORCLASS)) MorallyWrong))))))))
                          
(documentation realizesFormula EnglishLanguage "(conforms ?PROC ?FORMULA) describes how ?PROC follows the ideas outlined by the proposition represented by ?FORMULA.")

(domain realizesFormula 1 Process)
(domain realizesFormula 2 Formula)
(instance realizesFormula BinaryPredicate)
(subrelation realizesFormula represents)

;; A process conforms to a formula if and only if there exists a proposition such that:
;; a) the formula contains the information of the proposition.
;; b) the process is the realization of the proposition.
(<=>
  (realizesFormula ?PROCESS ?FORMULA)
  (exists (?PROP)
    (and
      (containsInformation ?FORMULA ?PROP)
      (realization ?PROCESS ?PROP))))

(documentation realizesFormulaSubclass EnglishLanguage "(conforms ?CPROC ?FORMULA) describes how ?CPROC follows the ideas outlined by the proposition represented by ?FORMULA.")

(domainSubclass realizesFormulaSubclass 1 Process)
(domain realizesFormulaSubclass 2 Formula)
(instance realizesFormulaSubclass BinaryPredicate)
(subrelation realizesFormulaSubclass represents)              
                                            
;; A subclass of Process conforms to a formula if there exists a proposition such that:
;; a) the formula contains the information of the proposition.
;; b) all instances of the subclass are realizations of the proposition.
(<=>
  (realizesFormulaSubclass ?CPROCESS ?FORMULA)
  (exists (?PROP)
    (and
      (containsInformation ?FORMULA ?PROP)
      (forall (?IPROCESS)
        (=>
          (instance ?IPROCESS ?CPROCESS)
          (realization ?IPROCESS ?PROP))))))

(documentation Deontology EnglishLanguage "Deontology is the ethical paradigm that judges the morality of an action 
based on the action adheres to a set of rules and principles.")
(subclass Deontology Ethics)

;; Hmm, how to do this is tricky.  Why say that the process is something YOU do?  It's just good for there to be some process realizing obligations, right?
;; Also, I'm not sure how to mix in the deontological language.
;; The below will be very experimental!
(=>
  (instance ?D Deontology)
  (exists (?PROP ?STATE)
    (and
      (subProposition ?PROP ?D)
      (containsInformation ?STATE ?PROP)
      (similar ?STATE
        (exists (?RULE ?DEONTIC)
          (and
            (instance ?DEONTIC DeonticAttribute)
            (modalAttribute ?RULE ?DEONTIC)
            (=>
              (modalAttribute ?RULE Obligation)
              (modalAttribute
                (exists (?PROCESS)
                  (realizesFormula ?PROCESS ?RULE)) MorallyGood))))))))

;; All instances of deontology have subpropositions that contain moral sentences.
;; These moral sentences are elements of a deontological theory.
;; I think this is good to say.  Clearly I want a "this sentence is a deontological sentence" shorthand".
;;                
(=>
  (instance ?D Deontology)
  (exists (?PROP ?SENT)
    (and
      (subProposition ?PROP ?D)
      (containsInformation ?SENT ?PROP)
      (instance ?SENT MoralSentence)
      (exists (?THEORY)
        (and 
          (instance ?THEORY DeontologicalTheory)
          (element ?SENT ?THEORY))))))
          
(=>
  (instance ?MT DeontologicalTheory)
  (exists (?MP)
    (and
      (instance ?MP Deontology)
      (forall (?S)
        (=>
          (element ?S ?MT)
          (exists (?PROP)
            (and
              (containsInformation ?S ?PROP)
              (subProposition ?PROP ?MP))))))))

;; What about something whacky like this?
;; There exists a moral theory and a moral philosophy such that
;; every sentence of the moral theory is contained in the moral philosophy
;; and for every sentence, there is a corresponding rule?
(exists (?MT ?MP)
  (and
    (instance ?MP Deontology)
    (instance ?MT ValueJudgmentTheory)
    (forall (?S)
      (=>
        (element ?S ?MT)
        (and
          (exists (?PROP)
            (and
              (containsInformation ?S ?PROP)
              (subProposition ?PROP ?MP)))
          (exists (?RULE ?DEONTIC)
            (and
              (instance ?DEONTIC DeonticAttribute)
              (modalAttribute ?RULE ?DEONTIC)
              (=>
                (equal ?DEONTIC Obligation)
                (equal ?S
                  (and
                    (modalAttribute
                      (exists (?PROC)
                        (realizesFormula ?PROC ?RULE)) MorallyGood)
                    (modalAttribute
                      (not
                        (exists (?PROC)
                          (realizesFormula ?PROC ?RULE))) MorallyBad)))))))))))
            
;; This can be modularly simplified!
(exists (?MT)
  (and
    (instance ?MT ValueJudgmentTheory)
    (forall (?S)
      (=>
        (element ?S ?MT)
        (exists (?RULE ?DEONTIC)
          (and
            (instance ?DEONTIC DeonticAttribute)
            (modalAttribute ?RULE ?DEONTIC)
            (=>
              (equal ?DEONTIC Obligation)
              (equal ?S
                (and
                  (modalAttribute
                    (exists (?PROC)
                      (realizesFormula ?PROC ?RULE)) MorallyGood)
                  (modalAttribute
                    (not
                      (exists (?PROC)
                        (realizesFormula ?PROC ?RULE))) MorallyBad))))))))))      
     
;; Let's just say that the standard deontic operators cover all deontolgical theories.
;; Assuming rights-based approaches etc can be translated into this form ;- )
(=>
  (instance ?MT ValueJudgmentTheory)
  (forall (?S)
    (=>
      (element ?S ?MT)
      (exists (?RULE ?DEONTIC)
        (and
          (instance ?DEONTIC DeonticAttribute)
          (modalAttribute ?RULE ?DEONTIC)
          (=>
            (equal ?DEONTIC Obligation)
            (equal ?S
              (and
                (modalAttribute
                  (exists (?PROC)
                    (realizesFormula ?PROC ?RULE)) MorallyGood)
                (modalAttribute
                  (not
                    (exists (?PROC)
                      (realizesFormula ?PROC ?RULE))) MorallyBad))))
          (=>
            (equal ?DEONTIC Prohibition)
            (equal ?S
              (modalAttribute
                (exists (?PROC)
                  (realizesFormula ?PROC ?RULE)) MorallyBad)))
          (=>
            (equal ?DEONTIC Permission)
            (equal ?S
              (forall (?CPROC)
                (=>
                  (realizesFormulaSubclass ?CPROC ?RULE)
                  (modalAttribute
                    (exists (?PREN)
                      (and
                        (instance ?PREN AutonomousAgentProcess)
                        (prevents ?PREN ?CPROC))) MorallyBad))))))))))

;; Let's see what it looks like if I place everything within the modalAttribute.
(=>
  (instance ?MT ValueJudgmentTheory)
  (forall (?S)
    (=>
      (element ?S ?MT)
      (exists (?RULE ?DEONTIC)
        (and
          (instance ?DEONTIC DeonticAttribute)
          (modalAttribute ?RULE ?DEONTIC)
          (=>
            (equal ?DEONTIC Obligation)
            (exists (?S2 ?G ?B)
              (and
                (element ?S2 ?MT)
                (equal ?G
                  (modalAttribute
                    (exists (?PROC)
                      (realizesFormula ?PROC ?RULE)) MorallyGood))
                (equal ?B
                  (modalAttribute
                    (not
                      (exists (?PROC)
                        (realizesFormula ?PROC ?RULE))) MorallyBad))
                (or 
                  (and (equal ?S ?G) (equal ?S2 ?B))
                  (and (equal ?S ?B) (equal ?S2 ?G))))))
          (=>
            (equal ?DEONTIC Prohibition)
            (equal ?S
              (modalAttribute
                (exists (?PROC)
                  (realizesFormula ?PROC ?RULE)) MorallyBad)))
          (=>
            (equal ?DEONTIC Permission)
            (exists (?S2 ?TEMP1 ?TEMP2)
              (and
                (element ?S2 ?MT)
                (equal ?TEMP1
                  (modalAttribute
                    (exists (?CPROC)
                      (realizesFormulaSubclass ?CPROC ?RULE)) MorallyNeutral))
                (equal ?TEMP2
                    (modalAttribute
                        (exists (?CPROC ?PREN)
                          (and
                            (realizesFormulaSubclass ?CPROC ?RULE)
                            (exists (?PREN)
                              (and
                                (instance ?PREN AutonomousAgentProcess)
                                (prevents ?PREN ?CPROC))))) MorallyBad))
                (or 
                  (and (equal ?S ?TEMP1) (equal ?S2 ?TEMP1))
                  (and (equal ?S ?TEMP2) (equal ?S2 ?TEMP2)))))))))))

;; I think to do this I need to define the structure of a SimpleValueJudgmentSentence as well as a ImperativeSentence.
;; Then I can say that for all parts either they are equal or they are an ImperativeSentence which is equivalent to the SimpleValueJudgmentSentence.
;; And I wish to say that the theories are equivalent but... in terms of what?
;; I'll also do the reverse mapping...?  Hmm.
;; Well, this is my OPPA Mapping Style!
;; Oh, I could actually just define the map, lol!

;; This function basically is what I've been calling "Deontology":
;; A mapping from imperative-type deontological sentences into value judgment-type deontological sentences
;; And then the mapping of Moral Judgments over the sentences as if to say, 
;; Society has considered these moral sentences and concluded them to be 'true' (or whatever else one does with them).
(documentation ImperativeToValueJudgmentSentenceFn EnglishLanguage "A UnaryFunction that maps simple imperative sentences into value judgment sentences.")
(domain ImperativeToValueJudgmentSentenceFn 1 SimpleImperativeSentence)
(range ImperativeToValueJudgmentSentenceFn ValueJudgmentSentence)
(instance ImperativeToValueJudgmentSentenceFn TotalValuedRelation)
(instance ImperativeToValueJudgmentSentenceFn UnaryFunction)

(=> 
  (and 
    (equal (ImperativeToValueJudgmentSentenceFn ?ITS) ?VJS)
    (equal ?ITS (modalAttribute ?RULE ?DEONTIC))
    (instance ?RULE Formula)
    (instance ?DEONTIC DeonticAttribute))
  (and
    (=>
      (equal ?DEONTIC Obligation)
      (equal ?VJS
        (and
          (modalAttribute
            (exists (?PROC)
              (realizesFormula ?PROC ?RULE)) MorallyGood)
          (modalAttribute
            (not
              (exists (?PROC)
                (realizesFormula ?PROC ?RULE))) MorallyBad))))
    (=>
      (equal ?DEONTIC Prohibition)
      (equal ?VJS
        (modalAttribute
          (exists (?PROC)
            (realizesFormula ?PROC ?RULE)) MorallyBad)))
    (=>
      (equal ?DEONTIC Permission)
      (equal ?VJS
        (forall (?CPROC)
          (=>
            (realizesFormulaSubclass ?CPROC ?RULE)
            (modalAttribute
              (exists (?PREN)
                (and
                  (instance ?PREN AutonomousAgentProcess)
                  (prevents ?PREN ?CPROC))) MorallyBad))))))) 

;; So now the 'too strong' claim above can be expressed very simply.
;; Now it's like, uhm, why even say this?
;; Because it's the kind of thing we'd probably like to be able to say.
(=>
  (instance ?MT ValueJudgmentTheory)
  (forall (?S)
    (=>
      (element ?S ?MT)
      (exists (?ITS)
        (and
          (instance ?ITS SimpleImperativeSentence)
          (equal ?S (ImperativeToValueJudgmentSentenceFn ?ITS)))))))  
;; (=> 
;;   (instance ?IT DeontologicalImperativeTheory)
;;   (exists (?DT)
;;     (and
;;       (instance ?DT DeontologicalValueJudgmentTheory)
;;       (forall (?S1)
;;         (=> 
;;           (element ?S1 ?IT)
;;           (and
;;             (=> 
;;               (not (instance ?S1 ?SimpleImperativeSentence))))))))

;; Let's do the inverse!
;; In this case it is simple -> simpl:
(documentation ValueJudgmentToImperativeSentenceFn EnglishLanguage "A UnaryFunction that maps simple value judgment sentences into imperative sentences.")
(domain ValueJudgmentToImperativeSentenceFn 1 SimpleValueJudgmentSentence)
(range ValueJudgmentToImperativeSentenceFn SimpleImperativeSentence)
(instance ValueJudgmentToImperativeSentenceFn TotalValuedRelation)
(instance ValueJudgmentToImperativeSentenceFn UnaryFunction)

;; This might be too simple and strong?  
;; There is the issue of the strength of an obligation etc, right?
;; One cannot go from imperatives to value judgments and back to imperatives.
;; A quite quirk is that going from a value judgment to an imperative and back says that:
;; It is MorallyBad to prevent someone from doing something that is MorallyNeutral?
(=> 
  (and 
    (equal (ValueJudgmentToImperativeSentenceFn ?VJS) ?ITS)
    (equal ?VJS (modalAttribute ?SITUATION ?MORALATTRIBUTE))
    (instance ?SITUATION Formula)
    (instance ?MORALATTRIBUTE MoralAttribute))
  (and
    (=>
      (equal ?MORALATTRIBUTE MorallyGood)
      (equal ?ITS 
        (modalAttribute ?SITUATION Obligation)))
    (=>
      (equal ?MORALATTRIBUTE MorallyBad)
      (equal ?ITS
        (modalAttribute ?SITUATION Prohibition)))
    (=>
      (equal ?MORALATTRIBUTE MorallyNeutral)
      (equal ?ITS
        (modalAttribute ?SITUATION Permission)))))

;; Might as well see how this looks and feels.
(documentation GenericImperativeToValueJudgmentSentenceFn EnglishLanguage "A UnaryFunction that maps simple imperative sentences into value judgment sentences in a very generic manner.")
(domain GenericImperativeToValueJudgmentSentenceFn 1 SimpleImperativeSentence)
(range GenericImperativeToValueJudgmentSentenceFn ValueJudgmentSentence)
(instance GenericImperativeToValueJudgmentSentenceFn TotalValuedRelation)
(instance GenericImperativeToValueJudgmentSentenceFn UnaryFunction)

;; So letting the Rule be fully general, such as 
;; (modalAttribute
;;   (exists (?PET)
;;     (and
;;         (instance ?PET DomesticAnimal)
;;         (located ?PET ?LOC))) Prohibition)
;; If this is prohibited, then it's morally bad for the pet to be located there.
;; Do we wish to say that it's morally bad to instantiate a process that realizes the pet being there?
;; Yeah, kind of, to be honest.
;; Yet it's also good to just say that it's bad, lol.
;; Maybe I like the generic versions.
;; And wish to do the realizing and the causal realization claims separately?
(=> 
  (and 
    (equal (GenericImperativeToValueJudgmentSentenceFn ?ITS) ?VJS)
    (equal ?ITS (modalAttribute ?RULE ?DEONTIC))
    (instance ?RULE Formula)
    (instance ?DEONTIC DeonticAttribute))
  (and
    (=>
      (equal ?DEONTIC Obligation)
      (equal ?VJS
        (and
          (modalAttribute ?RULE MorallyGood)
          (modalAttribute (not ?RULE) MorallyBad))))
    (=>
      (equal ?DEONTIC Prohibition)
      (equal ?VJS
        (modalAttribute ?RULE MorallyBad)))
    (=>
      (equal ?DEONTIC Permission)
      (equal ?VJS 
        (modalAttribute ?RULE MorallyNeutral)))))

;; This demonstrates that the 'second' rule of the obligation translation is not needed
;; For it is implied by the first in an Imperative Theory.
(=>
  (and
    (=>
      (modalAttribute ?FORMULA Obligation)
      (not
        (modalAttribute
          (not ?FORMULA) Permission)))
    (=>
      (not
        (modalAttribute
          (not ?FORMULA) Permission))
      (modalAttribute
        (not ?FORMULA) Prohibition)))
  (modalAttribute
    (not ?FORMULA) Prohibition))

;; For this rule, we only need to deal with the permissive case because Obligation ?F => Permission ?F. 
;; Thus this is not part of the translation between the imperative and value judgment languages.
;; It's actually a lemma of a moral theory ;- ).
;; One might claim that a prohibition on NOT ?FORMULA implies that preventing ?FORMULA is bad...,
;; Which probably does follow . . ..
;; I wonder if one needs to add agents in here, i.e., is choosing not to do something preventing myself?  Not quite...?
(forall (?RULE ?CPROC)
  (=>
    (and
      (realizesFormulaSubclass ?CPROC ?RULE)
      (modalAttribute ?RULE Permission))
    (modalAttribute
      (exists (?PREV)
        (and
          (instance ?PREV AutonomousAgentProcess)
          (prevents ?PREV ?CPROC))) Prohibition)))
    

;; Maybe it should be simplified to the following:
(=> 
  (and 
    (equal (GenericImperativeToValueJudgmentSentenceFn ?ITS) ?VJS)
    (equal ?ITS (modalAttribute ?RULE ?DEONTIC))
    (instance ?RULE Formula)
    (instance ?DEONTIC DeonticAttribute))
  (and
    (=>
      (equal ?DEONTIC Obligation)
      (equal ?VJS
        (modalAttribute ?RULE MorallyGood)))
    (=>
      (equal ?DEONTIC Prohibition)
      (equal ?VJS
        (modalAttribute ?RULE MorallyBad)))
    (=>
      (equal ?DEONTIC Permission)
      (equal ?VJS 
        (modalAttribute ?RULE MorallyNeutral)))))
        
;; This is also obviously too strong, I guess.
(=>
  (instance ?MT DeontologicalImperativeTheory)
  (forall (?S)
    (=>
      (element ?S ?MT)
      (exists (?VJS)
        (and
          (instance ?VJS SimpleValueJudgmentSentence)
          (equal ?S (ValueJudgmentToImperativeSentenceFn ?VJS)))))))

;; What about this?
;; For every imperative deontological theory,
;; For every part of a sentence that is a simple imperative sentence,
;; There exists some value judgment sentence that gets mapped to it.
(=>
  (instance ?MT DeontologicalImperativeTheory)
  (forall (?S)
    (=>
      (element ?S ?MT)
      (forall (?P)
        (=> 
          (and 
            (part ?P ?S)
            (instance ?P SimpleImperativeSentence))
          (exists (?VJS)
            (and
              (instance ?VJS SimpleValueJudgmentSentence)
              (equal ?P (ValueJudgmentToImperativeSentenceFn ?VJS)))))))))

;; For every deontological value judgment theory, 
;; For every part of each sentence that is a simple value judgment,
;; There exists some imperative statement of which this is a part.
;; Basically I'm constraining the form of the Formulas in the value judgments to be:
;; (a) realizing X is good
;; (b) realizing X is bad
;; (c) not realizing X is bad
;; (d) preventing Y from realizing X is bad.
;; Maybe I should just say this explicitly, lol.
;; And it clearly misses stuff like, "If X is bad to do, then preventing Y from realizing X is good."
;; But you can fit that into (A) by substituting "prevetning Y yfrom doing X" into X.
;; So, technically, this is going to be contradicted by the general rule for value judgment statements.
;; Mmm, no, I think the simple version works for this, actually.
(=>
  (instance ?MT ValueJudgmentTheory)
  (forall (?S)
    (=>
      (element ?S ?MT)
      (forall (?P)
        (=> 
          (and
            (part ?P ?S)
            (instance ?P SimpleValueJudgmentSentence))
          (exists (?ITS)
            (and
              (instance ?ITS SimpleImperativeSentence)
              (part ?P (ImperativeToValueJudgmentSentenceFn ?ITS)))))))))

;; Anyway, this can be corrected into a clean version.
(=>
  (instance ?MT ValueJudgmentTheory)
  (forall (?S)
    (=>
      (element ?S ?MT)
      (forall (?P)
        (=> 
          (and
            (part ?P ?S)
            (instance ?P SimpleValueJudgmentSentence))
          (exists (?ITS)
            (and
              (instance ?ITS SimpleImperativeSentence)
              (equal ?P (GenericImperativeToValueJudgmentSentenceFn ?ITS)))))))))

;; What I want to do really should just be done with proper structural recursion in terms of subFormula with pattern match...
;; (=>
;;   (instance ?VJT ValueJudgmentTheory)
;;   (exists (?IT)
;;     (forall (?VJS)
;;       (=>
;;         (element ?S ?MT)
;;         (forall (?PJS)
;;           (=>
;;             (part ?PJS ?VJS)
;;             (or
;;               (=>
;;                 (instance ?P SimpleImperativeSentence)
;;                 ())
;;               )))))))

(=>
  (instance ?S SimpleValueJudgmentSentence)
  (equal ?S
    (GenericImperativeToValueJudgmentSentenceFn
      (ValueJudgmentToImperativeSentenceFn ?S))))

(=>
  (instance ?S ImperativeSentence)
  (equal ?S
    (ValueJudgmentToImperativeSentenceFn
      (GenericImperativeToValueJudgmentSentenceFn ?S))))

(documentation VirtueEthics EnglishLanguage "Virtue ethics is the ethical paradigm that judges the morality of an action 
based on the character of the agent performing an action.  A virtuous agent is one who possesses virtues.  
'An action is right if and only if it is what a virtuous agent would characteristically (i.e., acting in caharacter) 
do in the circumstances' (On Virtue Ethics -- Right Action).")
(subclass VirtueEthics Ethics)

;; Linking Virtue Ethics with its Theories. V1
(=>
  (instance ?D VirtueEthics)
  (exists (?PROP ?SENT)
    (and
      (subProposition ?PROP ?D)
      (containsInformation ?SENT ?PROP)
      (instance ?SENT MoralSentence)
      (exists (?THEORY)
        (and
          (instance ?THEORY VirtueEthicsTheory)
          (element ?SENT ?THEORY))))))
          
;; For all instances of virtue ethics, there exists a virtue ethics theory
;; Such that all of its sentences are propositions of the virtue ethics instance.
;; Basically, the whole "moral sentence" thing is extraneous now :- ).
;; I feel as if we'd need greater precision to make the implication go both ways.  
;; We'd need to get more logical-implication level.
;; Yeah, I'm not sure how to avoid the trivialization without quantifying over subPropositionos, which is tricky as P is a subProposition of ~P.
(=>
  (instance ?MP VirtueEthics)
  (exists (?MT)
    (and
      (instance ?MT VirtueEthicsTheory)
      (forall (?S)
        (=>
          (element ?S ?MT)
          (exists (?PROP)
            (and
              (containsInformation ?S ?PROP)
              (subProposition ?PROP ?MP))))))))

;; So this is probably the best I can easily do.  
;; I see no reason why any 'theory' as a set of sentences can't be represented as a sentence of potentially infinite length by 'anding' each sentence together into one.
(=> 
  (instance ?MP VirtueEthics)
  (exists (?MTS)
    (and 
      (containsInformation ?MTS ?MP)
      (instance ?MTS VirtueEthicsSentence))))

;; Weirdly, quantifying over subPropositions seems too vague.
;; So we go over sentences in both directions.
(=>
  (instance ?MT VirtueEthicsTheory)
  (exists (?MP)
    (and
      (instance ?MP VirtueEthics)
      (forall (?S)
        (=>
          (element ?S ?MT)
          (exists (?PROP)
            (and
              (containsInformation ?S ?PROP)
              (subProposition ?PROP ?MP))))))))

;; So let's define a map from simple virtue ethics statements to value judgment statements.
(documentation SimpleVirtueToValueJudgmentSentenceFn EnglishLanguage "A UnaryFunction that maps simple virtue ethics sentences into value judgment sentences.")
(domain SimpleVirtueToValueJudgmentSentenceFn 1 SimpleVirtueEthicsSentence)
(range SimpleVirtueToValueJudgmentSentenceFn ValueJudgmentSentence)
(instance SimpleVirtueToValueJudgmentSentenceFn TotalValuedRelation)
(instance SimpleVirtueToValueJudgmentSentenceFn UnaryFunction)

;; I see how the target-centric virtue ethics is important here.
;; If one is ascribed the virtue of honesty, then when a decision involves the scope of honesty,
;; one's behavior resulting from the decision is likely to be morally good.
;; This doesn't extend beyond the relevant scope, however!
(=>
  (and
    (equal
      (SimpleVirtueToValueJudgmentSentenceFn ?SVS) ?VJS)
    (equal ?SVS
      (attribute ?AGENT ?VIRTUEATTRIBUTE))
    (instance ?AGENT AutonomousAgent))
  (and
    (=>
      (instance ?VIRTUEATTRIBUTE VirtueAttribute)
      (equal ?VJS
        (forall (?DECIDE ?DECISION)
          (=>
            (and
              (instance ?DECIDE Deciding)
              (agent ?DECIDE ?AGENT)
              (refers ?VIRTUEATTRIBUTE ?DECIDE)
              (result ?DECIDE
                (ClassToSetFn ?DECISION)))
            (modalAttribute
              (modalAttribute
                (exists (?INSTANCE)
                  (and
                    (agent ?INSTANCE ?AGENT)
                    (instance ?INSTANCE ?DECISION))) MorallyGood) Likely)))))
    (=>
      (instance ?VIRTUEATTRIBUTE ViceAttribute)
      (equal ?VJS
        (forall (?DECIDE ?DECISION)
          (=>
            (and
              (instance ?DECIDE Deciding)
              (agent ?DECIDE ?AGENT)
              (refers ?VIRTUEATTRIBUTE ?DECIDE)
              (result ?DECIDE
                (ClassToSetFn ?DECISION)))
            (modalAttribute
              (modalAttribute
                (exists (?INSTANCE)
                  (and
                    (agent ?INSTANCE ?AGENT)
                    (instance ?INSTANCE ?DECISION))) MorallyBad) Likely)))))))

;; Let's try to remove the decision middle-man.
;; This time, if a virtuous entity is known to have taken some behavior, then it's probably a good thing to do in general.
(=>
  (and
    (equal (SimpleVirtueToValueJudgmentSentenceFn ?SVS) ?VJS)
    (equal ?SVS (attribute ?AGENT ?VIRTUEATTRIBUTE))
    (instance ?AGENT AutonomousAgent))
  (and 
    (=> 
      (instance ?VIRTUEATTRIBUTE VirtueAttribute) 
      (equal ?VJS 
        (forall (?PROC)
          (=> 
            (and
              (subclass ?PROC AutonomousAgentProcess)
              (refers ?VIRTUEATTRIBUTE ?PROC)
              (exists (?INSTANCE)
                (and 
                  (agent ?INSTANCE ?AGENT)
                  (instance ?INSTANCE ?PROC))))
            (modalAttribute 
              (modalAttribute 
                (exists (?INSTANCE)
                  (instance ?INSTANCE ?PROC)) MorallyGood) Likely)))))
    (=>
      (instance ?VIRTUEATTRIBUTE ViceAttribute) 
      (equal ?VJS 
        (forall (?PROC)
          (=> 
            (and
              (subclass ?PROC AutonomousAgentProcess)
              (refers ?VIRTUEATTRIBUTE ?PROC)
              (exists (?INSTANCE)
                (and
                  (agent ?INSTANCE ?AGENT)
                  (instance ?INSTANCE ?PROC))))
            (modalAttribute 
              (modalAttribute 
                (exists (?INSTANCE)
                  (instance ?INSTANCE ?PROC)) MorallyBad) Likely)))))))

;; Maybe let's say that if it's likely for the virtuous agent to do X, then it's likely good to do X in general.
(=>
  (and
    (equal (SimpleVirtueToValueJudgmentSentenceFn ?SVS) ?VJS)
    (equal ?SVS (attribute ?AGENT ?VIRTUEATTRIBUTE))
    (instance ?AGENT AutonomousAgent))
  (and 
    (=> 
      (instance ?VIRTUEATTRIBUTE VirtueAttribute) 
      (equal ?VJS 
        (forall (?PROC)
          (=> 
            (and
              (subclass ?PROC AutonomousAgentProcess)
              (refers ?VIRTUEATTRIBUTE ?PROC)
              (modalAttribute
                (exists (?INSTANCE)
                  (and 
                    (agent ?INSTANCE ?AGENT)
                    (instance ?INSTANCE ?PROC))) Likely))
            (modalAttribute 
              (modalAttribute 
                (exists (?INSTANCE)
                  (instance ?INSTANCE ?PROC)) MorallyGood) Likely)))))
    (=>
      (instance ?VIRTUEATTRIBUTE ViceAttribute) 
      (equal ?VJS 
        (forall (?PROC)
          (=> 
            (and
              (subclass ?PROC AutonomousAgentProcess)
              (refers ?VIRTUEATTRIBUTE ?PROC)
              (modalAttribute
                (exists (?INSTANCE)
                  (and 
                    (agent ?INSTANCE ?AGENT)
                    (instance ?INSTANCE ?PROC))) Likely))
            (modalAttribute 
              (modalAttribute 
                (exists (?INSTANCE)
                  (instance ?INSTANCE ?PROC)) MorallyBad) Likely)))))))

;; We can generalize this beyond the 'agent' role!
;; We'll get a rule that probably too associatively considers an process a virtuous agent is a part of as 'good'.
(=>
  (and
    (equal
      (SimpleVirtueToValueJudgmentSentenceFn ?SVS) ?VJS)
    (equal ?SVS
      (attribute ?AGENT ?VIRTUEATTRIBUTE))
    (instance ?AGENT AutonomousAgent))
  (and
    (=>
      (instance ?VIRTUEATTRIBUTE VirtueAttribute)
      (equal ?VJS
        (forall (?PROC ?ROLE ?TIME ?PLACE)
          (=>
            (and
              (subclass ?PROC Process)
              (playsRoleInEventOfType ?AGENT ?ROLE ?PROC ?TIME ?PLACE)
              (refers ?VIRTUEATTRIBUTE ?PROC))
            (modalAttribute
              (modalAttribute
                (exists (?INSTANCE)
                  (instance ?INSTANCE ?PROC)) MorallyGood) Likely)))))
    (=>
      (instance ?VIRTUEATTRIBUTE ViceAttribute)
      (equal ?VJS
        (forall (?PROC)
          (=>
            (and
              (subclass ?PROC Process)
              (playsRoleInEventOfType ?AGENT ?ROLE ?PROC ?TIME ?PLACE)
              (refers ?VIRTUEATTRIBUTE ?PROC))
            (modalAttribute
              (modalAttribute
                (exists (?INSTANCE)
                  (instance ?INSTANCE ?PROC)) MorallyBad) Likely)))))))

;; Copied from Draft 3 for now . . . 
(documentation Change EnglishLanguage "Processes that involve altering a property of an Entity.")
(subclass Change Process)
(subclass InternalChange Change)

(=>
  (and
    (instance ?CHANGE Change)
    (patient ?CHANGE ?ENTITY))
  (exists (?PROPERTY)
    (or
      (and
        (holdsDuring
          (BeginFn
            (WhenFn ?CHANGE))
          (property ?ENTITY ?PROPERTY))
        (holdsDuring
          (EndFn
            (WhenFn ?CHANGE))
          (not
            (property ?ENTITY ?PROPERTY))))
      (and
        (holdsDuring
          (BeginFn
            (WhenFn ?CHANGE))
          (not
            (property ?ENTITY ?PROPERTY)))
        (holdsDuring
          (EndFn
            (WhenFn ?CHANGE))
          (property ?ENTITY ?PROPERTY))))))

;; Likewise, copied . . .
(documentation influences EnglishLanguage "The influence relation between instances of Entities (influences ?ENTITY1 ?ENTITY2 denotes that ?ENTITY has some effect on ?ENTITY2")
(domain influences 1 Entity)
(domain influences 2 Entity)
(instance influences BinaryPredicate)
(relatedInternalConcept influences causes)

(=>
  (causes ?P1 ?P2)
  (influences ?P1 ?P2))

(=>
  (influences ?E1 ?E2)
  (exists (?CHANGE ?PROCESS)
    (and
      (instance ?CHANGE Change)
      (patient ?CHANGE ?E2)
      (causes ?PROCESS ?CHANGE)
      (involvedInEvent ?PROCESS ?E1))))

;; If something is good, then a virtuous person is likely to do it in the appropriate situation.
(documentation SimpleValueJudgmentToVirtueSentenceFn EnglishLanguage "A UnaryFunction that maps simple value judgment sentences into simple virtue ethics sentences.")
(domain SimpleValueJudgmentToVirtueSentenceFn 1 SimpleValueJudgmentSentence)
(range SimpleValueJudgmentToVirtueSentenceFn VirtueEthicsSentence)
(instance SimpleValueJudgmentToVirtueSentenceFn TotalValuedRelation)
(instance SimpleValueJudgmentToVirtueSentenceFn UnaryFunction)

;; Maybe I need some sort of "Lemma": 
;; if a formula is good and there's some process that realizes the formula, then this process is good.
;; This is basically what I had in the old 'translation'..., and now that it's been simplified, 
;; it's an additional lemma!
;; Also, note, if the process is an autonomous agent process, the existence of an agent is provided by a lemma already in SUMO.

(=>
  (and
    (instance ?SVJ SimpleValueJudgmentSentence)
    (equal ?SVJ (modalAttribute ?SITUATION ?MORALATTRIBUTE))
    (realizesFormulaSubclass ?PROC ?SITUATION))
  (modalAttribute
    (exists (?INSTANCE)
      (instance ?INSTANCE ?PROC)) ?MORALATTRIBUTE))

;; Causing a non-process situation seems not so well dealt-with,
;; But we can suggest it by saying that if some agent-process causes the realization of a situation,
;; Then it's good/bad for it to exist if the situation is good/bad.
;; Adding in likely because the behavior could have additional consequences.
(=>
  (and 
    (instance ?SVJ SimpleValueJudgmentSentence)
    (equal ?SVJ (modalAttribute ?SITUATION ?MORALATTRIBUTE))
    (realizesFormulaSubclass ?PROC ?SITUATION)
    (causesSubclass ?CAUSE ?PROC)
    (subclass ?CAUSE AutonomousAgentProcess))
  (modalAttribute
    (modalAttribute
      (exists (?INSTANCE)
        (instance ?INSTANCE ?CAUSE)) ?MORALATTRIBUTE) Likely)) 

;; Probably I just need this Lemma to rule out perverse situations such as, "it's good for 1+1=2".
;; For every moral value judgment, there exists a behavior such that either,
;; 1) the situation refers to the behavior
;; 2) the situation refers to a process influenced by the behavior.
;; Can I make this a generic physical entity?  Or, meh, 
;; Maybe I should just make a predicate to denote the class of processes referred to by a situation?
;; It's confusing af.  The ontology here makes this sort of thing really hard to specify... 
(=>
  (and 
    (instance ?SVJ SimpleValueJudgmentSentence)
    (equal ?SVJ (modalAttribute ?SITUATION ?MORALATTRIBUTE))
    (instance ?SITUATION Formula))
  (exists (?PROC)
    (and 
      (subclass ?PROC AutonomousAgentProcess)
      (or
        (refers ?SITUATION (ClassToSetFn ?PROC))
        (exists (?PROC2)
          (and
            (refers ?SITUATION (ClassToSetFn ?PROC2))
            (subclass ?PROC2 Process)
            (influencs ?PROC ?PROC2)))))))

;; Maybe let's make a version that goes through Deciding and one version that doesn't!
;; Just use refers... excessively... because the goal isn't exactly to fill in all the details.
;; Use 'influnces'?  Ugh, this is hard!
;; (=>
;;   (and
;;     (equal (SimpleValueJudgmentToVirtueSentenceFn ?SVJ) ?VES)
;;     (equal ?SVJ (modalAttribute ?SITUATION ?MORALATTRIBUTE)
;;     (instance ?SITUATION Formula)
;;     (instance ?MORALATTRIBUTE MoralAttribute)
;;     (refers ?SITUATION ?PROC)
;;     (subclass ?PROC AutonomousAgentProcess)))
;;   (and  
;;     (=>
;;       (equal ?MORALATTRIBUTE MorallyGood))
;;     (=>
;;       (equal ?MORALATTRIBUTE MorallyBad))))

(documentation SimpleActionValueJudgmentToVirtueSentenceFn EnglishLanguage "A UnaryFunction that maps simple action value judgment sentences into simple virtue ethics sentences.")
(domain SimpleActionValueJudgmentToVirtueSentenceFn 1 ValueJudgmentSentence)
(range SimpleActionValueJudgmentToVirtueSentenceFn VirtueEthicsSentence)
(instance SimpleActionValueJudgmentToVirtueSentenceFn PartialValuedRelation)
(instance SimpleActionValueJudgmentToVirtueSentenceFn UnaryFunction)

;; So, leaving off anything about situations,
;; If an action is good/right and an agent possesses a virtue referring to this class of actions,
;; then it's likely the agent will take the action.
(=>
  (and 
    (equal (SimpleActionValueJudgmentToVirtueSentenceFn ?SAVJ) ?VES)
    (equal ?SAVJ (modalAttribute 
      (exists (?PROC)
        (instance ?PROC ?CLASS)) ?MORALATTRIBUTE)))
  (and
    (=>
      (equal ?MORALATTRIBUTE MorallyGood)
      (equal ?VES
        (forall (?AGENT)
          (=> 
            (and
              (instance ?AGENT VirtuousAgent)
              (exists (?VIRTUE)
                (and
                  (instance ?VIRTUE VirtueAttribute)
                  (attribute ?AGENT ?VIRTUE)
                  (refers ?VIRTUE ?PROC))))
            (modalAttribute 
              (exists (?PROC)
                (and
                  (instance ?PROC ?CLASS)
                  (agent ?PROC ?AGENT))) Likely)))))
    (=>
      (equal ?MORALATTRIBUTE MorallyBad)
      (equal ?VES
        (forall (?AGENT)
          (=> 
            (and
              (instance ?AGENT ViciousAgent)
              (exists (?VICE)
                (and 
                  (instance ?VICE ViceAtribute)
                  (attribute ?AGENT ?VICE)
                  (refers ?VICE ?PROC))))
            (modalAttribute 
              (exists (?PROC)
                (and
                  (instance ?PROC ?CLASS)
                  (agent ?PROC ?AGENT))) Likely)))))))

;; Ok, another stab at a more general variety:
;; Oh, maybe I could say that if ?S is morally good, then if an agent takes an action that makes ?S more likely, 
;; then ?S is likely virtuous in all virtues relevant to ?S!!!  Ahahaha, what a good idea!  
;; IncreasesLikeliHood and CausesProposition both... exist ;- D.

(=>
  (and
    (equal
      (SimpleValueJudgmentToVirtueSentenceFn ?SAVJ) ?VES)
    (equal ?SAVJ
      (modalAttribute ?FORMULA ?MORALATTRIBUTE)))
  (equal ?VES
    (forall (?AGENT ?PROC)
      (=>
        (and
          (instance ?AGENT AutonomousAgent)
          (subclass ?PROC AutonomousAgentProcess)
          (exists (?INSTANCE)
            (CausesProposition
              (and
                (agent ?INSTANCE ?AGENT)
                (instance ?INSTANCE ?PROC)) ?FORMULA)))
        (forall (?VIRTUE)
          (=>
            (and
              (instance ?VIRTUE MoralVirtueAttribute)
              (refers ?VIRTUE ?FORMULA))
            (modalAttribute
              (attribute ?AGENT ?VIRTUE) Likely)))))))

(=>
  (and
    (equal
      (SimpleValueJudgmentToVirtueSentenceFn ?SAVJ) ?VES)
    (equal ?SAVJ
      (modalAttribute ?FORMULA ?MORALATTRIBUTE)))
  (equal ?VES
    (forall (?AGENT ?PROC)
      (=>
        (and
          (instance ?AGENT AutonomousAgent)
          (subclass ?PROC AutonomousAgentProcess)
          (exists (?INSTANCE)
            (increasesLikelihood
              (and
                (agent ?INSTANCE ?AGENT)
                (instance ?INSTANCE ?PROC)) ?FORMULA)))
        (forall (?VIRTUE)
          (=>
            (and
              (instance ?VIRTUE MoralVirtueAttribute)
              (refers ?VIRTUE ?FORMULA))
            (modalAttribute
              (attribute ?AGENT ?VIRTUE) Likely)))))))

; (=>
;   (instance ?MT VirtueEthicsTheory)
;   (forall (?S)
;     (=>
;       (element ?S ?MT)  )))                              


(documentation Utilitarianism EnglishLanguage "Utilitarianism is the ethical paradigm that judges the morality of an action 
based on whether it maximizes the good over the bad, which is typically determined via a utility function.")
(subclass Utilitarianism Ethics)

;; MP for Moral Philosophy or Moral Predicate
(=>
  (instance ?MP Utilitarianism)
  (exists (?MTS)
    (and 
      (containsInformation ?MTS ?MP)
      (instance ?MTS UtilitarianSentence))))

(=>
  (instance ?MP Utilitarianism)
  (exists (?MT)
    (and
      (instance ?MT UtilitarianTheory)
      (forall (?S)
        (=>
          (element ?S ?MT)
          (exists (?P)
            (and
              (containsInformation ?S ?P)
              (subProposition ?P ?MP))))))))

;; So for a Utilitarian Proposition, there is some sentence that contains its information.
;; And there is a Utilitarian theory such that each sentence is a sub-string of this mega-sentence
;; And each sentence also corresponds to a su-proposition of the utilitarian proposition.
(=>
  (instance ?MP Utilitarianism)
  (exists (?MT ?MTS)
    (and
      (containsInformation ?MTS ?MP)
      (instance ?MTS UtilitarianSentence)
      (instance ?MT UtilitarianTheory)
      (forall (?S)
        (=>
          (element ?S ?MT)
          (and
              (subString ?S ?MTS)
              (exists (?P)
                (and
                  (containsInformation ?S ?P)
                  (subProposition ?P ?MP)))))))))

;; Now that we can take the concatenation of a theory of sentences,
;; We can say that for a moral philosophy, 
;; there exists a moral theory whose 'and'-sentence contains the information of the philosophy.
(=>
  (instance ?MP Utilitarianism)
  (exists (?MT ?MTS)
    (and
      (instance ?MT UtilitarianTheory)
      (equal ?MTS (ListAndFn (SetToListFn ?MT)))
      (containsInformation ?MTS ?MP))))

;; And it might be nice to add that each sentence corresponds to a particular sub-proposition.  Y not?
(=>
  (instance ?MP Utilitarianism)
  (exists (?MT ?MTS)
    (and
      (instance ?MT UtilitarianTheory)
      (equal ?MTS (ListAndFn (SetToListFn ?MT)))
      (containsInformation ?MTS ?MP)
      (forall (?S)
        (=>
          (element ?S ?MT)
          (exists (?P)
            (and
              (containsInformation ?S ?P)
              (subProposition ?P ?MP))))))))

;; The latter part is perhaps extraneous now, actually!  
(=>
  (instance ?MT UtilitarianTheory)
  (exists (?MP)
    (and 
      (instance ?MP Utilitarianism)
      (containsInformation (ListAndFn (SetToListFn ?MT)) ?MP)
      (forall (?S)
        (=>
          (element ?S ?MT)
          (exists (?P)
            (and
              (containsInformation ?S ?P)
              (subProposition ?P ?MP))))))))

(documentation UtilityAssignmentToValueJudgmentSentence EnglishLanguage "A UnaryFunction that maps utility assignment sentences into simple value judgment sentences.")
(domain UtilityAssignmentToValueJudgmentSentence 1 UtilityAssignmentSentence)
(range UtilityAssignmentToValueJudgmentSentence SimpleValueJudgmentSentence)
(instance UtilityAssignmentToValueJudgmentSentence TotalValuedRelation)
(instance UtilityAssignmentToValueJudgmentSentence UnaryFunction)

;; So if the utility is positive, it's good; negative, it's bad; and if it's zero, then it's neutral.
;; Super clean and simple!
(=> 
  (and 
    (equal (UtilityAssignmentToValueJudgmentSentence ?UAS) ?VJS)
    (equal ?UAS (equal (UtilityFormulaFn ?FORMULA) ?VALUE))
    (instance ?FORMULA Formula)
    (instance ?VALUE Number))
  (and
    (=>
      (greaterThan ?VALUE 0)
      (equal ?VJS
        (modalAttribute ?FORMULA MorallyGood)))
    (=>
      (lessThan ?VALUE 0)
      (equal ?VJS
        (modalAttribute ?FORMULA MorallyBad)))
    (=>
      (equal ?VALUE 0)
      (equal ?VJS 
        (modalAttribute ?FORMULA MorallyNeutral)))))

(documentation ValueJudgmentToUtilityAssignmentSentence EnglishLanguage "A UnaryFunction that maps value judgment sentences to utility assignment sentences.")
(domain ValueJudgmentToUtilityAssignmentSentence 1 SimpleValueJudgmentSentence)
(range ValueJudgmentToUtilityAssignmentSentence UtilityAssignmentSentence)
(instance ValueJudgmentToUtilityAssignmentSentence TotalValuedRelation)
(instance ValueJudgmentToUtilityAssignmentSentence UnaryFunction)

;; So this is also trivial.  We just need to assign 1 to good, -1 to bad, and 0 to neutral.
;; If there's a notion of the strengths of moral value judgments, this ports over cleanly.
(=> 
  (and 
    (equal (ValueJudgmentToUtilityAssignmentSentence ?VJS) ?UAS)
    (equal ?VJS (modalAttribute ?FORMULA ?MORALATTRIBUTE))
    (instance ?FORMULA Formula)
    (instance ?MORALATTRIBUTE MoralAttribute))
  (and
    (=>
      (equal ?MORALATTRIBUTE MorallyGood)
      (equal ?UAS 
        (equal (UtilityFormulaFn ?FORMULA) 1)))
    (=>
      (equal ?MORALATTRIBUTE MorallyBad)
      (equal ?UAS
        (equal (UtilityFormulaFn ?FORMULA) -1)))
    (=>
      (equal ?MORALATTRIBUTE MorallyNeutral)
      (equal ?UAS
        (equal (UtilityFormulaFn ?FORMULA) 0)))))

(documentation ValueJudgmentToUtilityAssignmentLikelihoodSentence EnglishLanguage "A UnaryFunction that maps value judgment sentences to utility assignment likelihood sentences.")
(domain ValueJudgmentToUtilityAssignmentLikelihoodSentence 1 SimpleValueJudgmentSentence)
(range ValueJudgmentToUtilityAssignmentLikelihoodSentence UtilitarianSentence)
(instance ValueJudgmentToUtilityAssignmentLikelihoodSentence TotalValuedRelation)
(instance ValueJudgmentToUtilityAssignmentLikelihoodSentence UnaryFunction)

;; What I said in draft 3 is that if something is morally good, then its utility is likely greater than zero.
;; And we can do this sort of translation (over which moral judgments may pass.)
(=> 
  (and 
    (equal (ValueJudgmentToUtilityAssignmentSentence ?VJS) ?UAS)
    (equal ?VJS (modalAttribute ?FORMULA ?MORALATTRIBUTE))
    (instance ?FORMULA Formula)
    (instance ?MORALATTRIBUTE MoralAttribute))
  (and
    (=>
      (equal ?MORALATTRIBUTE MorallyGood)
      (equal ?UAS
        (modalAttribute 
          (greaterThan (UtilityFormulaFn ?FORMULA) 0) Likely)))
    (=>
      (equal ?MORALATTRIBUTE MorallyBad)
      (equal ?UAS
        (modalAttribute 
          (lessThan (UtilityFormulaFn ?FORMULA) 0) Likely)))
    (=>
      (equal ?MORALATTRIBUTE MorallyNeutral)
      (equal ?UAS
        (modalAttribute 
          (equal (UtilityFormulaFn ?FORMULA) 0) Likely)))))

(documentation UtilityAssignmentToValueJudgmentSentence EnglishLanguage "A UnaryFunction that maps utility assignment sentences into simple value judgment sentences.")
(domain UtilityAssignmentToValueJudgmentSentence 1 UtilityAssignmentSentence)
(range UtilityAssignmentToValueJudgmentSentence SimpleValueJudgmentSentence)
(instance UtilityAssignmentToValueJudgmentSentence TotalValuedRelation)
(instance UtilityAssignmentToValueJudgmentSentence UnaryFunction)

(documentation HedonisticUtilitarianism EnglishLanguage "Hedonistic Utilitarianism is a form of utilitarianism that focuses on maximizing pleasure and minimizing pain in evaluating the moral value of an action.")
(subclass HedonisticUtilitarianism Utilitarianism)

(documentation Consequentialism EnglishLanguage "Consequentialism is a moral theory that holds that 'whether an act is morally right depends only on consequences (as opposed to the circumstances or the intrinsic nature of the act or anything that happens before the act)' (Stanford Encyclopedia of Philosophy).")
(subclass Consequentialism Utilitarianism)                    