;; Draft 3 -- because dealing with moral judgments in terms of classes instead of instances 
;; seems substantial enough to warrant possibly revamping a lot!
;; I will not repeat unchanged elements from the Ethics Kifs folder.

(documentation DecidingSubclass EnglishLanguage "The subclass of Selecting where the agent opts for one course of action 
out of a set of multiple possibilities that are open to him/ her, which are represented as subclasses of Process, 
some instance of which can be enacted.")
(subclass DecidingSubclass Selecting)
(termFormat EnglishLanguage DecidingSubclass "deciding")

;; If a subclass of Process is being decided upon by an agent
;; The agent is capable of enacting an instance of the SubProcess
(=>
    (and 
        (instance ?DECIDE DecidingSubclass)
        (agent ?DECIDE ?AGENT)
        (patient ?DECIDE ?CPROCESS))
    (capability ?CPROCESS agent ?AGENT))

;; Draft 2, being nitpicky, maybe the agent only believes it's capable
;; And will decide on the action based on the belief without actually being able to 🤪
(=>
    (and 
        (instance ?DECIDE DecidingSubclass)
        (agent ?DECIDE ?AGENT)
        (patient ?DECIDE ?CPROCESS))
    (believes ?AGENT 
        (capability ?CPROCESS agent ?AGENT)))

;; If an agent decides on a class of behaviors, then there exists an instance of this class of behaviors
;; that is an intentional process and of which the agent is an agent.
;; A bit of a stretch as agents don't strictly _need_ to act on their conclusions.
;; Just trying to sketch a "class" version of the "instance" Deciding in SUMO.
(=>
    (and
        (instance ?DECIDE DecidingSubclass)
        (agent ?DECIDE ?AGENT)
        (result ?DECIDE ?CPROCESS))
    (exists (?IPROCESS)
        (and
            (instance ?IPROCESS ?CPROCESS)
            (instance ?IPROCESS IntentionalProcess)
            (agent ?IPROCESS ?AGENT))))

;; While the above essentially imply that the patient of a Deciding(Subclass) is a subclass of Process
;; I'd like to make it clear.
(=>
    (and 
        (instance ?DECIDE DecidingSubclass)
        (patient ?DECIDE ?CPROCESS))
    (subclass ?CPROCESS Process))

;; The same for Deciding
(=>
    (and 
        (instance ?DECIDE Deciding)
        (patient ?DECIDE ?IPROCESS))
    (instance ?IPROCESS Process))

;; I think this one is pretty much fine, lol.
;; Actually, it's a bit weird: it makes it seem as if one is choosing between subclasses of LegalDecision,
;; namely, LegalAcquittal, LegalAward, LegalConviction, LegalDismissal, and Sentencing.
;; One could stipulate that sometimes one is choosing among particular instances of a single class of procesess,
;; for exmaple, what sort of conviction to sentence someone to.  
;; A counter-argument would be that one is actually choosing among hitherto unspecified subclasses of LegalConviction.
;; Here, when there's a Legal Decision, there is an act of deciding on a type of legal decision that takes place earlier
;; than the decision.  And the decision is an instance of the type of legal decision decided upon.
;; Which, tbh, seems better than just dealing in instances.
;; (I should really look into what the intended semantics of instances are.  )
(=>
    (instance ?DECISION LegalDecision)
    (exists (?DECIDE)
        (and
            (instance ?DECIDE DecidingSubclass)
            (earlier
                (WhenFn ?DECIDE)
                (WhenFn ?DECISION))
            (result ?DECIDE ?LEGALDECISIONPROCESS)
            (instance ?DECISION ?LEGALDECISIONPROCESS))))

;; This shouldn't be deciding.
(=>
    (ratingsAgent ?RATING ?AGENT)
    (exists (?PROCESS)
        (and
            (instance ?PROCESS Deciding)
            (agent ?PROCESS ?AGENT)
            (result ?PROCESS ?RATING))))

;; So there are only two uses of Deciding in SUMO's KB anyway.
;; The rule in GameCall seems fine as it's vague.  Should probably be Judging.  I don't know enough about it.
;; Voting should perhaps be a subclass of Selecting, not Deciding
;; As one is often not actually selecting courses of action.
;; However, it would seem that all the uses of Voting and VotingFn do not refer to the result at all!
;; Thus all of the subclasses of Deciding can also be subclasses of DecidingSubclass!

;; Resolution could just as well be a subclass of Deciding!
(documentation ResolutionSubclass EnglishLanguage "Any instance of DecidingSubclass which is conducted at a FormalMeeting 
and where the agent is an Organization.")
(subclass ResolutionSubclass Decidingsubclass)

(=>
    (instance ?RESOLUTION ResolutionSubclass)
    (exists (?AGENT ?MEETING)
        (and
            (instance ?AGENT Organization)
            (agent ?RESOLUTION ?AGENT)
            (subProcess ?RESOLUTION ?MEETING)
            (instance ?MEETING FormalMeeting))))

;; I think that covers all the Decision: Instance -> Class update!  Yay 🥳
;; The first question is: what needs to be changed to suite the DecisionSubclass?

;; Fields of Study are now classes!
(documentation Ethics EnglishLanguage "Ethics is the normative science of the conduct of human beings living in society, 
which judges this conduct to be right or wrong, to be good or bad, or in some similar way. (An Introduction to Ethics (LIllie, 1948))")
(subclass Ethics Philosophy)
(subclass Ethics Science)

(documentation MoralNihilism EnglishLanguage "'Moral Nihilism is the view that nothing is morally wrong' (SEP - Moral Skepticism). 
Moral Nihilism can also be defined as 'the view that there are no moral facts' (Ethics: The Fundamentals).")
(subclass MoralNihilism Ethics)

(documentation Deontology EnglishLanguage "Deontology is the ethical paradigm that judges the morality of an action 
based on the action adheres to a set of rules and principles.")
(subclass Deontology Ethics)

(documentation Utilitarianism EnglishLanguage "Utilitarianism is the ethical paradigm that judges the morality of an action 
based on whether it maximizes the good over the bad, which is typically determined via a utility function.")
(subclass Utilitarianism Ethics)

(documentation VirtueEthics EngnlishLanguage "Virtue ethics is the ethical paradigm that judges the morality of an action 
based on the character of the agent performing an action.  A virtuous agent is one who possesses virtues.  
'An action is right if and only if it is what a virtuous agent would characteristically (i.e., acting in caharacter) 
do in the circumstances' (On Virtue Ethics -- Right Action).")
(subclass VirtueEthics Ethics)

(documentation HedonisticUtilitarianism EnglishLanguage "Hedonistic Utilitarianism is a form of utilitarianism that focuses on maximizing pleasure and minimizing pain in evaluating the moral value of an action.")
(subclass HedonisticUtilitarianism Utilitarianism)

(documentation Consequentialism EnglishLanguage "Consequentialism is a moral theory that holds that 'whether an act is morally right depends only on consequences (as opposed to the circumstances or the intrinsic nature of the act or anything that happens before the act)' (Stanford Encyclopedia of Philosophy).")
(subclass Consequentialism Utilitarianism)

;; Repeated only because I added to them ;- )

;; MorallyGood, VirtueAttribute, VirtuousAgent and the vicious versions can remain the same ✅
;; AutonomousAgentProcess is good.

; (=>
;     (instance ?JUDGE MoralJudging)
;     (exists (?BEHAVE ?MORAL)
;         (and 
;             (instance ?BEHAVE AutonomousAgentProcess)
;             (instance ?MORAL MoralAttribute)
;             (patient ?JUDGE ?BEHAVE)
;             (result ?JUDGE 
;                 (modalAttribute ?BEHAVE ?MORAL)))))
;; The above (draft 2) is wrong because because ?BEHAVE is a Process, not a Formula.  

;; If there is an instance ?J of Moral Judging, then there exists a class of autonomous agent behavior ?CB and a moral judgment ?M, 
;; such that it is judged to me ?M for there to exist an instance ?IB of ?CB.
;; -- This actually makes more sense!
(=>
    (instance ?JUDGE MoralJudging)
    (exists (?CBEHAVE ?MORAL)
        (and 
            (subclass ?CBEHAVE AutonomousAgentProcess)
            (instance ?MORAL MoralAttribute)
            (patient ?JUDGE ?CBEHAVE)
            (result ?JUDGE 
                (modalAttribute 
                    (exists (?IBEHAVE) 
                        (instance ?IBEHAVE ?CBEHAVE)) ?MORAL)))))

;; Isn't this just type inhabitation or sometihng?
(documentation hasInstance EnglishLanguage "Auxiliary predicate to simplify definitions.")
(subclass hasInstance Predicate)
(domainSubclass hasInstance 1 Class)

(=> 
    (instance hasInstance ?REL)
    (valence ?REL 1))

(<=>
    (hasInstance ?CLASS)
    (exists (?INSTANCE)
        (instance ?INSTANCE ?CLASS)))

;; Using hasInstance: It's bad for there to be an instance of this class of autonomous behavior >:D.
(=>
    (instance ?JUDGE MoralJudging)
    (exists (?CBEHAVE ?MORAL)
        (and 
            (subclass ?CBEHAVE AutonomousAgentProcess)
            (instance ?MORAL MoralAttribute)
            (patient ?JUDGE ?CBEHAVE)
            (result ?JUDGE 
                (modalAttribute 
                    (hasInstance ?CBEHAVE) ?MORAL)))))

;;  We might wish to say that if there is a result of a moral judgment, then it is of the form that something judged morally.
(=> 
    (and
        (instance ?JUDGE MoralJudging)
        (result ?JUDGE ?RESULT))
    (exists (?JUDGED ?MORAL) 
        (equals ?RESULT
            (modalAttribute ?JUDGED ?MORAL))))

;; If there is an instance ?J of moral judging, then there exists an autonomous agent behavior ?B and a moral judgment ?M,
;; such that it is judged to be ?M that there is an instance of ?B.
;; -- A bit weird.  There's some precedence in SUMO.
;; I suppose we wish to get at the case where one is simply judging a particular behavior as GOOD or BAD without any clear sense of generalization. 
(=>
    (instance ?JUDGE MoralJudging)
    (exists (?BEHAVE ?MORAL)
        (and 
            (instance ?MORAL MoralAttribute)
            (patient ?JUDGE ?BEHAVE)
            (result ?JUDGE 
                (modalAttribute
                    (instance ?BEHAVE AutonomousAgentProcess) ?MORAL)))))

;; Maybe I wish to say that if there is a case of moral judging ?J, then it is either of the above cases:
;; Judging any instance of a class of behaviors ?M or judging a particular instance to be ?M.
(=>
    (instance ?JUDGE MoralJudging)
    (or
        (exists (?CBEHAVE ?MORAL)
        (and 
            (subclass ?CBEHAVE AutonomousAgentProcess)
            (instance ?MORAL MoralAttribute)
            (patient ?JUDGE ?CBEHAVE)
            (result ?JUDGE 
                (modalAttribute 
                    (exists (?IBEHAVE) 
                        (instance ?IBEHAVE ?CBEHAVE)) ?MORAL))))
        (exists (?BEHAVE ?MORAL)
        (and 
            (instance ?MORAL MoralAttribute)
            (patient ?JUDGE ?BEHAVE)
            (result ?JUDGE 
                (modalAttribute
                    (instance ?BEHAVE AutonomousAgentProcess) ?MORAL))))))

;; Ethics refers to the moral judging of processes (behavior) of members of groups (aka society, lol).
;; Not sure how to get the "normative science" part in.  I think there's a lot of hidden baggage in the term "normative".
(and 
    (refers Ethics ?JUDGE)
    (instance ?JUDGE MoralJudging)
    (instance ?MORAL MoralAttribute)
    (instance ?GROUP Group)
    (instance ?BEHAVE AutonomousAgentProcess)
    (member ?MEMB ?GROUP)
    (agent ?BEHAVE ?MEMB)
    (patient ?JUDGE ?BEHAVE)
    (result ?JUDGE 
        (modalAttribute ?BEHAVE ?MORAL)))
;; The above (draft 2) can be refined because the instance ?MORAL implies the behavior and the moral judgment.

;; This is tricky because I'm including both classes and instances.  Maybe I should drop instances for now.
;; Anyway, I wish to include the idea that the moral judgment is of a member of a group
(and 
    (refers Ethics ?JUDGE)
    (instance ?JUDGE MoralJudging)
    (instance ?GROUP Group)
    (member ?MEMB ?GROUP)
    (patient ?JUDGE ?BEHAVE)
    (=>
        (instance ?BEHAVE AutonomousAgentProcess)
        (agent ?BEHAVE ?MEMB))
    (=> 
        (subclass ?BEHAVE AutonomousAgentProcess)
        (capability ?BEHAVE agent ?MEMB)))

;; Let's add that the agent of the moral judgment is either an inclusive subgroup or a member of the group (with a bit of redundancy!)
(and 
    (refers Ethics ?JUDGE)
    (instance ?JUDGE MoralJudging)
    (instance ?GROUP Group)
    (member ?MEMB ?GROUP)
    (patient ?JUDGE ?BEHAVE)
    (=>
        (instance ?BEHAVE AutonomousAgentProcess)
        (agent ?BEHAVE ?MEMB))
    (=> 
        (subclass ?BEHAVE AutonomousAgentProcess)
        (capability ?BEHAVE agent ?MEMB))
    (agent ?JUDGE ?AGENT)
    (or
        (member ?AGENT ?GROUP)
        (part ?AGENT ?GROUP)))

;; I wish to add a minimalistic one that doesn't bother with the societal context
(and 
    (refers Ethics ?JUDGE)
    (instance ?JUDGE MoralJudging))

;; "Moral nihilism is the view that there are no moral facts." (Ethics: The Fundamentals)
;; There is no moral judging (with behavior and moral judgments) that is a fact.
;; Curiously, I think this doesn't need to be changed at all!
(and 
    (refers MoralNihilism ?STATE)
    (instance ?STATE Statement)
    (equal ?STATE 
        (not 
            (exists (?JUDGE) 
                (and 
                    (instance ?JUDGE MoralJudging)
                    (result ?JUDGE ?MORALSTATEMENT)
                    (instance ?MORALSTATEMENT Fact))))))


;; "Nothing is morally wrong." (from SEP Moral Skepticism); 
;; technically, this would be a noncognitivist nihilism, I suppose (citing Ethics: The Fundamentals)
(and 
    (refers MoralNihilism ?STATE)
    (instance ?STATE Statement)
    (equal ?STATE 
        (not 
            (exists (?BEHAVE) 
                (and 
                    (instance ?BEHAVE AutonomousAgentProcess)
                    (modalAttribute ?BEHAVE MorallyBad))))))

;; There does not exist a class of behaviors for which there being an instance is morally bad.
(and 
    (refers MoralNihilism ?STATE)
    (instance ?STATE Statement)
    (equal ?STATE 
        (not 
            (exists (?CBEHAVE) 
                (and 
                    (subclass ?CBEHAVE AutonomousAgentProcess)
                    (modalAttribute (hasInstance ?CBEHAVE) MorallyBad))))))

;; Or we have the following phrasing: forall classes of behaviors, it's not the case that it's bad for there to be an instance thereof.
(and 
    (refers MoralNihilism ?STATE)
    (instance ?STATE Statement)
    (equal ?STATE 
        (forall (?CBEHAVE)
            (=> 
                (subclass ?CBEHAVE AutonomousAgentProcess)
                (not 
                    (modalAttribute (hasInstance ?CBEHAVE) MorallyBad))))))                    


;; (conformsFormula ?BEHAVE ?RULE)
;; (conforms ?OBJ ?PROP)
;; (partition Physical Object Process)
;; (domain conforms 1 Object)
;; --> I cannot use conforms for this purpose.

; (=> 
;     (conformsFormula ?OBJ ?FORMULA)
;     (exists (?PROP)
;         (and 
;             (containsInformation ?FORMULA ?PROP)
;             (conforms ?OBJ ?PROP))))

;; Maybe rename this to realizes formula for natural language ease?
;; A process conforms to a formula if and only if there exists a proposition such that:
;; a) the formula contains the information of the proposition.
;; b) the process is the realization of the proposition.
(<=> 
    (realizesFormula ?PROCESS ?FORMULA)
    (exists (?PROP)
        (and 
            (containsInformation ?FORMULA ?PROP)
            (realization ?PROCESS ?PROP))))

;; A subclass of Process conforms to a formula if there exists a proposition such that:
;; a) the formula contains the information of the proposition.
;; b) all instances of the subclass are realizatinos of the proposition.
(<=> 
    (realizesFormulaSubclass ?CPROCESS ?FORMULA)
    (exists (?PROP)
        (and 
            (containsInformation ?FORMULA ?PROP)
            (forall (?IPROCESS)
                (=> 
                    (instance ?IPROCESS ?CPROCESS)
                    (realization ?IPROCESS ?PROP))))))

;; Probably the 'or' and the 'rule' should be swapped!
;; Maybe I want some auxiliary "Judges Behavior Morally Good" shorthand... some predicate?
(and 
    (refers Deontology ?STATE)
    (instance ?STATE Statement)
    (equal ?STATE
        (exists (?RULE)
            (or
                (and 
                    (modalAttribute ?RULE Obligation)
                    (=>
                        (realizesFormula ?BEHAVE ?RULE)
                        (and 
                            (instance ?JUDGE MoralJudging)
                            (result ?JUDGE
                                (modalAttribute ?BEHAVE MorallyGood))))
                    (=>
                        (not 
                            (realizesFormula ?BEHAVE ?RULE))
                        (and 
                            (instance ?JUDGE MoralJudging)
                            (result ?JUDGE
                                (modalAttribute ?BEHAVE MorallyBad)))))
                (and 
                    (modalAttribute ?RULE Prohibition)
                    (=> 
                        (realizesFormula ?BEHAVE ?RULE)
                        (and 
                            (instance ?JUDGE MoralJudging)
                            (result ?JUDGE
                                (modalAttribute ?BEHAVE MorallyBad)))))
                (and 
                    (modalAttribute ?RULE Permission)
                    (=> 
                        (and 
                            (realizesFormula ?BEHAVE1 ?RULE)
                            (prevents ?BEHAVE2 ?BEHAVE1)
                            (instance ?BEHAVE2 AutonomousAgentProcess))
                        (and 
                            (instance ?JUDGE MoralJudging)
                            (result ?JUDGE 
                                (modalAttribute ?BEHAVE2 MorallyBad)))))))))

;; The next step is to make the class version.
;; One trick here is that the "class" aspect is less relevant here.
;; All I'm saying is that "if a behavior realizes the rule", "then it's good/bad".
;; But one thing that needs to be fixed is: a process is not a formula and thus modalAttribute cannot be applied to it.
;; I might also wish to make a version with confersNorm unifying the norm-confering agent with the morally judging agent!
;; I'm also changing the structure so that we separately state that the rule is either an obligation, prohibition, or permission.
;; And then we state what each case entails.
;; I think this works and we don't need to deal with the "class" aspect explicitly, for it's implicit in the existential quantification.
;; We probably wish to grapple with the notion of judging a whole class of behaviors to be good/bad tho.
;; Take one here is: if a rule is an obligation, then there exists a moral judgment
;; that it is good for there to exist an instance of a behavior realizing the rule.
;; and it is morally bad for there to NOT exist a behavior realizing the obligatory rule.
;; Before, dealing only with instances, I just said that it's bad if it doesn't satisfy the obligation (which would require a notion of temporality and mutual exclusivity).
;; With the existential claim, we seem quite a bit safer.
;; As before, the prohibition is simply the opposite of the obligation.
;; For permission, I'll say that there is a judgment such that for all classes of behaviors that realize the permission,
;; It is bad for there to exist an instance of behavior that prevents any of these classes from being instantiated.
(and 
    (refers Deontology ?STATE)
    (instance ?STATE Statement)
    (equal ?STATE
        (exists (?RULE)
            (and
                (or
                    (modalAttribute ?RULE Obligation)
                    (modalAttribute ?RULE Prohibition)
                    (modalAttribute ?RULE Permission))
                (=>
                    (modalAttribute ?RULE Obligation)
                    (exists (?JUDGE)
                        (and
                            (instance ?JUDGE MoralJudging)
                            (result ?JUDGE
                                (and 
                                    (modalAttribute 
                                        (exists (?BEHAVE)
                                            (and 
                                                (realizesFormula ?BEHAVE ?RULE)
                                                (instance ?BEHAVE AutonomousAgentProcess))) MorallyGood)
                                    (modalAttribute 
                                        (not 
                                            (exists (?BEHAVE)
                                                (and 
                                                    (realizesFormula ?BEHAVE ?RULE)
                                                    (instance ?BEHAVE AutonomousAgentProcess))) MorallyBad)))))))      
                (=>
                    (modalAttribute ?RULE Prohibition)
                    (exists (?JUDGE)
                        (and
                            (instance ?JUDGE MoralJudging)
                            (result ?JUDGE
                                (modalAttribute 
                                        (exists (?BEHAVE)
                                            (and 
                                                (realizesFormula ?BEHAVE ?RULE)
                                                (instance ?BEHAVE AutonomousAgentProcess))) MorallyBad)))))
                (=> 
                    (modalAttribute ?RULE Permission)
                    (exists (?JUDGE)
                        (and
                            (instance ?JUDGE MoralJudging)
                            (result ?JUDGE
                                (forall (CBEHAVE)
                                    (=> 
                                        (and
                                            (subclass ?CBEHAVE AutonomousAgentProcess)
                                            (realizesFormulaSubclass ?CBEHAVE ?RULE))                              
                                        (modalAttribute 
                                            (exists (?BEHAVE)
                                                (and
                                                    (instance ?BEHAVE AutonomousAgentProcess)
                                                    (prevents ?CBEHAVE ?BEHAVE))) MorallyBad)))))))))))
             
;;; I'll add the confersNorm part below.
;; Also, apparently Law is a subattribute of obligation, Legal of permission, and Illegal of prohibition.  
;; LegislativeBill (a proposed law) is the only outlier that should be fixed, probably
;; So there's an agent that declares this rule and this agent is the one that judges adherence to be good/bad.
;; Some deontological theories may not wish to make this distinction.  
;; I note that (domain confersNorm 1 Entity), so possibly one could say that the rule is conferred by mathematical necessity.
;; In which caset he agents doing the judging are distinct.
(and 
    (refers Deontology ?STATE)
    (instance ?STATE Statement)
    (equal ?STATE
        (exists (?RULE)
            (and
                (instance ?DEONTIC DeonticAttribute)
                (modalAttribute ?RULE ?DEONTIC)
                (exists (?AGENT) 
                    (confersNorm ?AGENT ?RULE ?DEONTIC))
                (=>
                    (modalAttribute ?RULE Obligation)
                    (exists (?JUDGE)
                        (and
                            (agent ?JUDGE ?AGENT)
                            (instance ?JUDGE MoralJudging)
                            (result ?JUDGE
                                (and 
                                    (modalAttribute 
                                        (exists (?BEHAVE)
                                            (and 
                                                (realizesFormula ?BEHAVE ?RULE)
                                                (instance ?BEHAVE AutonomousAgentProcess))) MorallyGood)
                                    (modalAttribute 
                                        (not 
                                            (exists (?BEHAVE)
                                                (and 
                                                    (realizesFormula ?BEHAVE ?RULE)
                                                    (instance ?BEHAVE AutonomousAgentProcess))) MorallyBad)))))))      
                (=>
                    (modalAttribute ?RULE Prohibition)
                    (exists (?JUDGE)
                        (and
                            (agent ?JUDGE ?AGENT)
                            (instance ?JUDGE MoralJudging)
                            (result ?JUDGE
                                (modalAttribute 
                                        (exists (?BEHAVE)
                                            (and 
                                                (realizesFormula ?BEHAVE ?RULE)
                                                (instance ?BEHAVE AutonomousAgentProcess))) MorallyBad)))))
                (=> 
                    (modalAttribute ?RULE Permission)
                    (exists (?JUDGE)
                        (and
                            (agent ?JUDGE ?AGENT)
                            (instance ?JUDGE MoralJudging)
                            (result ?JUDGE
                                (forall (CBEHAVE)
                                    (=> 
                                        (and
                                            (subclass ?CBEHAVE AutonomousAgentProcess)
                                            (realizesFormulaSubclass ?CBEHAVE ?RULE))                              
                                        (modalAttribute 
                                            (exists (?BEHAVE)
                                                (and
                                                    (instance ?BEHAVE AutonomousAgentProcess)
                                                    (prevents ?CBEHAVE ?BEHAVE))) MorallyBad)))))))))))

;; Let's try to do a Classy version
; (and 
;     (refers Deontology ?STATE)
;     (instance ?STATE Statement)
;     (equal ?STATE
;         (exists (?RULE)
;             (and
;                 (instance ?DEONTIC DeonticAttribute)
;                 (modalAttribute ?RULE ?DEONTIC)
;                 (=>
;                     (and 
;                         (modalAttribute ?RULE Obligation)
;                         (exists (?CBEHAVE)
;                             (and 
;                                 (realizesFormulaSubclass ?CBEHAVE ?RULE))
;                                 (subclass ?CBEHAVE AutonomousAgentProcess)))
;                     ...
;                     ...
;                     ...
;; Actually, it's harder to make sense of how to do this.  
;; What I'm doing with the existence of an instance IS the class-sensitive approach. 
;; So I think I'll just move on for now :- )
;; Next up is virtue ethics and its similar sets etc :- )

;; “the study of behavior and its value” --- I might wish to actually do MY definition in SUMO :D
(and 
    (refers Ethics ?BEHAVE)
    (instance ?BEHAVE AutonomousAgentProcess)
    (refers Ethics ?VALUE)
    (instance ?VALUE SubjectiveAssessmentAttribute))

;; lolol, this doesn't work.
;; There's no good entry in SUMO atm for "value" (which I began sketching in draft 2)
;; Moreover, the current map to Subjective Assessment Attributes doesn't work because 
;; Attributes only apply to objects.
;; Maybe I'll get back to this later.

;; The idea here is that if E1 and E2 are similar to agent A, 
;; Then A is likely to make similar judgments with regard to E1 and E2.
(=> 
    (similar ?A ?E1 ?E2)
    (=>
        (and
            (instance ?J1 Judging)
            (agent ?J1 ?A)
            (patient ?J1 ?E1)
            (result ?J1 ?O1)
            (instance ?J2 Judging)
            (agent ?J2 ?A)
            (patient ?J2 ?E2)
            (result ?J2 ?O2))
        (modalAttribute (equal ?O1 ?O2) Likely)))

;; Equal is too strong, yet there's the problem of a recursive definition.
(=> 
    (similar ?A ?E1 ?E2)
    (=>
        (and
            (instance ?J1 Judging)
            (agent ?J1 ?A)
            (patient ?J1 ?E1)
            (result ?J1 ?O1)
            (instance ?J2 Judging)
            (agent ?J2 ?A)
            (patient ?J2 ?E2)
            (result ?J2 ?O2))
        (modalAttribute (similar ?A ?O1 ?O2) Likely)))

;; This might help.
(=>
    (equal ?E1 ?E2)
    (forall (?A)
        (similar ?A ?E1 ?E2)))

(<=> 
    (similar ?A ?E1 ?E2)
    (similar ?A ?E2 ?E1))

;; Maybe we could connect the specific similarity "measure" to the ontological similar
;; By saying that if S1 and S2 are similar with regard to a binary predicate, 
;; Then it's likely that they're similar for all agents :D.
;; (#ObviouslyARoughDraft)
(=>
    (similarSetsWithBP ?BP ?S1 ?S2)
    (modalAttribute 
        (forall (?A) 
            (Similarity ?A ?S1 ?S2) Likely)))

;; I've decided that for Virtue Ethics, I should just use the ontological similarity.

;; It seems I only 'reified' versions of DecisionOptionFn that don't specify whether they're classes or instances.

;; One is deciding from a non-empty set of options.
(=>
    (instance ?DECIDE Deciding)
    (instance (DecisionOptionFn ?DECIDE) NonNullSet))

;; Let's just do a subclass version for now!
(documentation DecisionSubclassOptionFn EnglishLanguage "A UnaryFunction that maps an instance of DecidingSubclass 
to the set of possibilities that are available.")
(domain DecisionSubclassOptionFn 1 DecidingSubclass)
(instance DecisionSubclassOptionFn TotalValuedRelation)
(instance DecisionSubclassOptionFn UnaryFunction)
(range DecisionSubclassOptionFn Set)

(<=>
    (element ?P (DecisionSubclassOptionFn ?DECIDE))
    (patient ?DECIDE ?P))

;; It is morally good for there to be an instance of a class of behaviors according to agent J
;; if and only if J believes that if a virtuous agent is making a decision with a similar set of options 
;; to the decision resulting in this behvior class, then the virtuous agent is likely to come to the same conclusion.
;; Should I include the agent taking the behavior? 
(and 
    (refers VirtueEthics ?STATE)
    (instance ?STATE Statement)
    (equals ?STATE 
        (<=>
            (and
                (instance ?JUDGE MoralJudging)
                (agent ?JUDGE ?AGENTJ)
                (patient ?JUDGE
                    (modalAttribute 
                        (hasInstance ?CBEHAVE) MorallyGood)))
            (believes ?AGENTJ
                (=>
                    (and 
                        (instance ?DECIDE DecidingSubclass)
                        (result ?DECIDE ?CBEHAVE)
                        (subclass ?CBEHAVE AutonomousAgentProcess)
                        (agent ?DECIDEV ?AGENTV)
                        (instance ?AGENTV VirtuousAgent)
                        (instance ?DECIDEV DecidingSubclass)
                        (similar ?AGENTJ (DecisionSubclassOptionFn ?DECIDE) (DecisioSubclassnOptionFn ?DECIDEV)))
                    (modalAttribute (result ?DECIDEV ?CBEHAVE) Likely))))))

(and 
    (refers VirtueEthics ?STATE)
    (instance ?STATE Statement)
    (equals ?STATE 
        (<=>
            (and
                (instance ?JUDGE MoralJudging)
                (agent ?JUDGE ?AGENTJ)
                (patient ?JUDGE
                    (modalAttribute 
                        (exists (?IBEHAVE)
                            (instance ?IBEHAVE ?CBEHAVE)) MorallyBad)))
            (believes ?AGENTJ
                (=>
                    (and 
                        (instance ?DECIDE DecidingSubclass)
                        (result ?DECIDE ?CBEHAVE)
                        (agent ?DECIDEV ?AGENTV)
                        (instance ?AGENTV ViciousAgent)
                        (instance ?DECIDEV DecidingSubclass)
                        (similar ?AGENTJ (DecisionSubclassOptionFn ?DECIDE) (DecisioSubclassnOptionFn ?DECIDEV)))
                    (modalAttribute (result ?DECIDEV ?CBEHAVE) Likely))))))

;; I think that's roughly it for Virtue Ethics.  
;; I'm a bit unsure about lumping the decision resulting in the behavior and the virtuous agent's decision together.
;; Maybe I want to use two implications?  
;; Except they're technically equivalent with metarial implication.
;; Maybe I could move the part about the decision being made for CBEHAVE into the moral judging expression?

;; Let's just copy this over.
(documentation UtilityFn EnglishLanguage "A UnaryFunction that maps an instance of AutonomousAgentProcess 
to the net utility it creates.  In the case of hedonistic utilitarianism, this may be (pleasure - pain).")
(domain UtilityFn 1 AutonomousAgentProcess)
(instance UtilityFn TotalValuedRelation)
(instance UtilityFn UnaryFunction)
(range UtilityFn RealNumber)

(documentation UtilitySubclassFn EnglishLanguage "A UnaryFunction that maps a subclass of AutonomousAgentProcess 
to the net utility it creates.  In the case of hedonistic utilitarianism, this may be (pleasure - pain).  
For the case of classes of behavior, this could be understood as an expectation.")
(domainSubclass UtilitySubclassFn 1 AutonomousAgentProcess)
(instance UtilitySublassFn TotalValuedRelation)
(instance UtilitySubclassFn UnaryFunction)
(range UtilitySubclassFn RealNumber)

;; A class of behaviors is good to enact if its expected utility is positive.
;; All complications are swept into the magical utility function.
(and
    (refers Utilitarianism ?STATE)
    (instance ?STATE Statement)
    (equals ?STATE
        (and
            (<=>
                (and
                    (instance ?JUDGE MoralJudging)
                    (result ?JUDGE
                        (modalAttribute (hasInstance ?CBEHAVE) MorallyGood)))
                (greaterThan (UtilitySubclassFn ?CBEHAVE) 0))
            (<=>
                (and
                    (instance ?JUDGE MoralJudging)
                    (result ?JUDGE
                        (modalAttribute (hasInstance ?CBEHAVE) MorallyBad)))
                (lessThan (UtilitySubclassFn ?CBEHAVE) 0)))))

(and
    (refers Utilitarianism ?STATE)
    (instance ?STATE Statement)
    (equals ?STATE
        (and
            (<=>
                (and
                    (instance ?JUDGE MoralJudging)
                    (result ?JUDGE
                        (modalAttribute (hasInstance ?CBEHAVE) MorallyGood)))
                (=> 
                    (hasInstance ?CBEHAVE)
                    (modalAttribute 
                        (and 
                            (instance ?IBEHAVE ?CBEHAVE)
                            (greaterThan (utilityFn ?IBEHAVE) 0)) Likely)))
            (<=>
                (and
                    (instance ?JUDGE MoralJudging)
                    (result ?JUDGE
                        (modalAttribute (hasInstance ?CBEHAVE) MorallyBad)))
                (=> 
                    (hasInstance ?CBEHAVE)
                    (modalAttribute 
                        (and 
                            (instance ?IBEHAVE ?CBEHAVE)
                            (lessThan (utilityFn ?IBEHAVE) 0)) Likely))))))

;; As in draft two, an action is morally good if it is an action of the class with 
;; the highest expected utility available in a decision process.
;; This avoids mention of cases where behavior is judged w/o being the result of a decision process.
;; An action class is morally bad if there exists a better option.  (We could add that it should have negative utility, lol.)
(and
    (refers Utilitarianism ?STATE)
    (instance ?STATE Statement)
    (equals ?STATE
        (and
            (=>
                (and
                    (instance ?DECIDE DecidingSubclass)
                    (result ?DECIDE ?CBEHAVE)
                    (subclass ?CBEHAVE AutonomousAgentProcess)
                    (forall (?OPTION)
                        (=> 
                            (member ?OPTION (DecisionSubclassOptionFn ?DECIDE))
                            (greaterThanOrEqualTo (UtilitySubclassFn ?CBEHAVE) (UtilitySubclassFn ?OPTION)))))
                (and
                    (instance ?JUDGE MoralJudging)
                    (result ?JUDGE
                        (modalAttribute (hasInstance ?CBEHAVE) MorallyGood))))
            (=>
                (and
                    (instance ?DECIDE DecidingSubclass)
                    (result ?DECIDE ?CBEHAVE)
                    (subclass ?CBEHAVE AutonomousAgentProcess)
                    (exists (?OPTION)
                        (=> 
                            (member ?OPTION (DecisionSubclassOptionFn ?DECIDE))
                            (lessThan (UtilitySubclassFn ?CBEHAVE) (UtilitySubclassFn ?OPTION)))))
                (and
                    (instance ?JUDGE MoralJudging)
                    (result ?JUDGE
                        (modalAttribute (hasInstance ?CBEHAVE) MorallyBad))))))

;; We can throw in the agent.
(and
    (refers Utilitarianism ?STATE)
    (instance ?STATE Statement)
    (equals ?STATE
        (=>
            (and
                (instance ?DECIDE DecidingSubclass)
                (agent ?DECIDE ?AGENT)
                (result ?DECIDE ?CBEHAVE)
                (subclass ?CBEHAVE AutonomousAgentProcess)
                (forall (?OPTION)
                    (=> 
                        (member ?OPTION (DecisionSubclassOptionFn ?DECIDE))
                        (greaterThanOrEqualTo (UtilitySubclassFn ?CBEHAVE) (UtilitySubclassFn ?OPTION)))))
            (and
                (instance ?JUDGE MoralJudging)
                (result ?JUDGE
                    (modalAttribute 
                        (exists (?IBEHAVE)
                            (and
                                (instance ?IBEHAVE ?CBEHAVE)
                                (agent ?IBEHAVE ?AGENT))) MorallyGood))))))

;; TODO: it would be cool to define a specific utility function that results in consequentialism
;; Thus demonstrating the modularity of the ontology.

;; Maybe we could say something like this?
;; If you do something that's morally bad, then it's likely that you've got a vice!
(=>
    (and
        (modalAttribute (hasInstance ?CBEHAVE) MorallyBad)
        (subclass ?CBEHAVE AutonomousAgentProcess)
        (exists ?IBEHAVE)
            (and
                (instance ?IBEHAVE ?CBEHAVE)
                (agent ?IBEHAVE ?AGENT)))
    (modalAttribute (attribute ?AGENT ViceAttribute) Likely))






